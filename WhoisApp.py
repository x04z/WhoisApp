import streamlit as st
from streamlit_option_menu import option_menu
import pandas as pd
import requests
import time
from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED
import socket
import struct
import ipaddress
from urllib.parse import quote
import math
import altair as alt 
import json 
import io 
import re 

# --- Excelã‚°ãƒ©ãƒ•ç”Ÿæˆç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
from openpyxl import Workbook
from openpyxl.utils.dataframe import dataframe_to_rows
from openpyxl.chart import BarChart, Reference, Series
from openpyxl.chart.label import DataLabelList
from openpyxl.chart.axis import ChartLines
from openpyxl.chart.layout import Layout, ManualLayout
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(layout="wide", page_title="æ¤œç´¢å¤§è‡£", page_icon="ğŸŒ")

# ==========================================
# ğŸ› ï¸ è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ (st.secretsåˆ©ç”¨)
# ==========================================
IS_PUBLIC_MODE = False
try:
    if "ENV_MODE" in st.secrets and st.secrets["ENV_MODE"] == "public":
        IS_PUBLIC_MODE = True
except FileNotFoundError:
    IS_PUBLIC_MODE = False
# ==========================================

# --- è¨­å®š ---
MODE_SETTINGS = {
    "å®‰å®šæ€§é‡è¦– (2.5ç§’å¾…æ©Ÿ/å˜ä¸€ã‚¹ãƒ¬ãƒƒãƒ‰)": {
        "MAX_WORKERS": 1, 
        "DELAY_BETWEEN_REQUESTS": 2.5 
    },
    "é€Ÿåº¦å„ªå…ˆ (1.4ç§’å¾…æ©Ÿ/2ã‚¹ãƒ¬ãƒƒãƒ‰)": {
        "MAX_WORKERS": 2, 
        "DELAY_BETWEEN_REQUESTS": 1.4 
    }
}
IP_API_URL = "http://ip-api.com/json/{ip}?fields=status,country,countryCode,isp,org,query,message"
IPINFO_API_URL = "https://ipinfo.io/{ip}" 
RDAP_BOOTSTRAP_URL = "https://rdap.apnic.net/ip/{ip}" 

RATE_LIMIT_WAIT_SECONDS = 120 
  
RIR_LINKS = {
    'RIPE': 'https://apps.db.ripe.net/db-web-ui/#/query?searchtext={ip}',
    'ARIN': 'https://search.arin.net/rdap/?query={ip}',
    'APNIC': 'https://wq.apnic.net/static/search.html',
    'JPNIC': 'https://www.nic.ad.jp/ja/whois/ja-gateway.html',
    'AFRINIC': 'https://www.afrinic.net/whois',
    'ICANN Whois': 'https://lookup.icann.org/',
}

# ğŸ”— ãƒªãƒ³ã‚¯é›†
SECONDARY_TOOL_BASE_LINKS = {
    'VirusTotal': 'https://www.virustotal.com/',
    'Whois.com': 'https://www.whois.com/',
    'Who.is': 'https://who.is/',
    'DomainSearch.jp': 'https://www.domainsearch.jp/',
    'Aguse': 'https://www.aguse.jp/',
    'IP2Proxy': 'https://www.ip2proxy.com/',
    'DNS Checker': 'https://dnschecker.org/',
    'DNSlytics': 'https://dnslytics.com/',
    'IP Location': 'https://iplocation.io/',
    'CP-WHOIS': 'https://doco.cph.jp/whoisweb.php',
    }

COUNTRY_CODE_TO_RIR = {
    'JP': 'JPNIC', 'CN': 'APNIC', 'AU': 'APNIC', 'KR': 'APNIC', 'IN': 'APNIC',
    'ID': 'APNIC', 'MY': 'APNIC', 'NZ': 'APNIC', 'SG': 'APNIC',
    'TH': 'APNIC', 'VN': 'APNIC', 'PH': 'APNIC', 'PK': 'APNIC', 
    'BD': 'APNIC', 'HK': 'APNIC', 'TW': 'APNIC', 'NP': 'APNIC', 'LK': 'APNIC',
    'MO': 'APNIC', 
    'US': 'ARIN', 'CA': 'ARIN',
    'ZA': 'AFRINIC', 'EG': 'AFRINIC', 'NG': 'AFRINIC',
    'KE': 'AFRINIC', 'DZ': 'AFRINIC', 'MA': 'AFRINIC', 'GH': 'AFRINIC', 
    'CM': 'AFRINIC', 'TN': 'AFRINIC', 'ET': 'AFRINIC', 'TZ': 'AFRINIC',
    'DE': 'RIPE', 'FR': 'RIPE', 'GB': 'RIPE', 'RU': 'RIPE',
    'NL': 'RIPE', 'IT': 'RIPE', 'ES': 'RIPE', 'PL': 'RIPE', 
    'TR': 'RIPE', 'UA': 'RIPE', 'SA': 'RIPE', 'IR': 'RIPE', 
    'CH': 'RIPE', 'SE': 'RIPE', 'NO': 'RIPE', 'DK': 'RIPE', 
    'BE': 'RIPE', 'AT': 'RIPE', 'GR': 'RIPE', 'PT': 'RIPE',
    'IE': 'RIPE', 'FI': 'RIPE', 'CZ': 'RIPE', 'RO': 'RIPE',
    'HU': 'RIPE', 'IL': 'RIPE', 'KZ': 'RIPE', 'BG': 'RIPE',
    'HR': 'RIPE', 'RS': 'RIPE', 'AE': 'RIPE', 'QA': 'RIPE',
}

COUNTRY_CODE_TO_NUMERIC_ISO = {
    'AF': 4, 'AL': 8, 'DZ': 12, 'AS': 16, 'AD': 20, 'AO': 24, 'AI': 660, 'AQ': 10, 'AG': 28, 'AR': 32,
    'AM': 51, 'AW': 533, 'AU': 36, 'AT': 40, 'AZ': 31, 'BS': 44, 'BH': 48, 'BD': 50, 'BB': 52, 'BY': 112,
    'BE': 56, 'BZ': 84, 'BJ': 204, 'BM': 60, 'BT': 64, 'BO': 68, 'BA': 70, 'BW': 72, 'BV': 74, 'BR': 76,
    'VG': 92, 'IO': 86, 'BN': 96, 'BG': 100, 'BF': 854, 'BI': 108, 'KH': 116, 'CM': 120, 'CA': 124, 'CV': 132,
    'KY': 136, 'CF': 140, 'TD': 148, 'CL': 152, 'CN': 156, 'CX': 162, 'CC': 166, 'CO': 170, 'KM': 174, 'CG': 178,
    'CD': 180, 'CK': 184, 'CO': 170, 'CR': 188, 'HR': 191, 'CU': 192, 'CY': 196, 'CZ': 203, 'DK': 208, 'DJ': 262, 'DM': 212,
    'DO': 214, 'EC': 218, 'EG': 818, 'SV': 222, 'GQ': 226, 'ER': 232, 'EE': 233, 'ET': 231, 'FK': 238, 'FO': 234,
    'FJ': 242, 'FI': 246, 'FR': 250, 'GF': 254, 'PF': 258, 'TF': 260, 'GA': 266, 'GM': 270, 'GE': 268, 'DE': 276,
    'GH': 288, 'GI': 292, 'GR': 300, 'GL': 304, 'GD': 308, 'GP': 312, 'GU': 316, 'GT': 320, 'GN': 324, 'GW': 624,
    'GY': 328, 'HT': 332, 'HM': 334, 'VA': 336, 'HN': 340, 'HK': 344, 'HU': 348, 'IS': 352, 'IN': 356, 'ID': 360,
    'IR': 364, 'IQ': 368, 'IE': 372, 'IL': 376, 'IT': 380, 'CI': 384, 'JM': 388, 'JP': 392, 'JO': 400, 'KZ': 398,
    'KE': 404, 'KI': 296, 'KP': 408, 'KR': 410, 'KW': 414, 'KG': 417, 'LA': 418, 'LV': 428, 'LB': 422, 'LS': 426,
    'LR': 430, 'LY': 434, 'LI': 438, 'LT': 440, 'LU': 442, 'MO': 446, 'MK': 807, 'MG': 450, 'MW': 454, 'MY': 458,
    'MV': 462, 'ML': 466, 'MT': 470, 'MH': 584, 'MQ': 474, 'MR': 478, 'MU': 480, 'YT': 175, 'MX': 484, 'FM': 583,
    'MD': 498, 'MC': 492, 'MN': 496, 'MS': 500, 'MA': 504, 'MZ': 508, 'MM': 104, 'NA': 516, 'NR': 520, 'NP': 524,
    'NL': 528, 'AN': 530, 'NC': 540, 'NZ': 554, 'NI': 558, 'NE': 562, 'NG': 566, 'NU': 570, 'NF': 574, 'MP': 580,
    'NO': 578, 'OM': 512, 'PK': 586, 'PW': 585, 'PS': 275, 'PA': 591, 'PG': 598, 'PY': 600, 'PE': 604, 'PH': 608,
    'PN': 612, 'PL': 616, 'PT': 620, 'PR': 630, 'QA': 634, 'RE': 638, 'RO': 642, 'RU': 643, 'RW': 646, 'SH': 654,
    'KN': 659, 'LC': 662, 'PM': 666, 'VC': 670, 'WS': 882, 'SM': 674, 'ST': 678, 'SA': 682, 'SN': 686, 'RS': 688,
    'SC': 690, 'SL': 694, 'SG': 702, 'SK': 703, 'SI': 705, 'SB': 90, 'SO': 706, 'ZA': 710, 'GS': 239, 'ES': 724,
    'LK': 144, 'SD': 736, 'SR': 740, 'SJ': 744, 'SZ': 748, 'SE': 752, 'CH': 756, 'SY': 760, 'TW': 158, 'TJ': 762,
    'TZ': 834, 'TH': 764, 'TL': 626, 'TG': 768, 'TK': 772, 'TO': 776, 'TT': 780, 'TN': 788, 'TR': 792, 'TM': 795,
    'TC': 796, 'TV': 798, 'UG': 800, 'UA': 804, 'AE': 784, 'GB': 826, 'US': 840, 'UM': 581, 'UY': 858, 'UZ': 860,
    'VU': 548, 'VE': 862, 'VN': 704, 'VI': 850, 'WF': 876, 'EH': 732, 'YE': 887, 'ZM': 894, 'ZW': 716
}

COUNTRY_JP_NAME = {
    "AF": "ã‚¢ãƒ•ã‚¬ãƒ‹ã‚¹ã‚¿ãƒ³","AL": "ã‚¢ãƒ«ãƒãƒ‹ã‚¢","DZ": "ã‚¢ãƒ«ã‚¸ã‚§ãƒªã‚¢","AS": "ã‚¢ãƒ¡ãƒªã‚«é ˜ã‚µãƒ¢ã‚¢","AD": "ã‚¢ãƒ³ãƒ‰ãƒ©","AO": "ã‚¢ãƒ³ã‚´ãƒ©",
    "AI": "ã‚¢ãƒ³ã‚®ãƒ©","AQ": "å—æ¥µ","AG": "ã‚¢ãƒ³ãƒ†ã‚£ã‚°ã‚¢ãƒ»ãƒãƒ¼ãƒ–ãƒ¼ãƒ€","AR": "ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³","AM": "ã‚¢ãƒ«ãƒ¡ãƒ‹ã‚¢","AW": "ã‚¢ãƒ«ãƒ","AU": "ã‚ªãƒ¼ã‚¹ãƒˆãƒ©ãƒªã‚¢",
    "AT": "ã‚ªãƒ¼ã‚¹ãƒˆãƒªã‚¢","AZ": "ã‚¢ã‚¼ãƒ«ãƒã‚¤ã‚¸ãƒ£ãƒ³","BS": "ãƒãƒãƒ","BH": "ãƒãƒ¼ãƒ¬ãƒ¼ãƒ³","BD": "ãƒãƒ³ã‚°ãƒ©ãƒ‡ã‚·ãƒ¥","BB": "ãƒãƒ«ãƒãƒ‰ã‚¹","BY": "ãƒ™ãƒ©ãƒ«ãƒ¼ã‚·",
    "BE": "ãƒ™ãƒ«ã‚®ãƒ¼","BZ": "ãƒ™ãƒªãƒ¼ã‚º","BJ": "ãƒ™ãƒŠãƒ³","BM": "ãƒãƒŸãƒ¥ãƒ¼ãƒ€","BT": "ãƒ–ãƒ¼ã‚¿ãƒ³","BO": "ãƒœãƒªãƒ“ã‚¢","BA": "ãƒœã‚¹ãƒ‹ã‚¢ãƒ»ãƒ˜ãƒ«ãƒ„ã‚§ã‚´ãƒ“ãƒŠ",
    "BW": "ãƒœãƒ„ãƒ¯ãƒŠ","BR": "ãƒ–ãƒ©ã‚¸ãƒ«","BN": "ãƒ–ãƒ«ãƒã‚¤","BG": "ãƒ–ãƒ«ã‚¬ãƒªã‚¢","BF": "ãƒ–ãƒ«ã‚­ãƒŠãƒ•ã‚¡ã‚½","BI": "ãƒ–ãƒ«ãƒ³ã‚¸","KH": "ã‚«ãƒ³ãƒœã‚¸ã‚¢","CM": "ã‚«ãƒ¡ãƒ«ãƒ¼ãƒ³",
    "CA": "ã‚«ãƒŠãƒ€","CV": "ã‚«ãƒ¼ãƒœãƒ™ãƒ«ãƒ‡","CF": "ä¸­å¤®ã‚¢ãƒ•ãƒªã‚«å…±å’Œå›½","TD": "ãƒãƒ£ãƒ‰","CL": "ãƒãƒª","CN": "ä¸­å›½","CO": "ã‚³ãƒ­ãƒ³ãƒ“ã‚¢","CR": "ã‚³ã‚¹ã‚¿ãƒªã‚«",
    "HR": "ã‚¯ãƒ­ã‚¢ãƒã‚¢","CU": "ã‚­ãƒ¥ãƒ¼ãƒ","CY": "ã‚­ãƒ—ãƒ­ã‚¹","CZ": "ãƒã‚§ã‚³","DK": "ãƒ‡ãƒ³ãƒãƒ¼ã‚¯","DJ": "ã‚¸ãƒ–ãƒ","DM": "ãƒ‰ãƒŸãƒ‹ã‚«å›½","DO": "ãƒ‰ãƒŸãƒ‹ã‚«å…±å’Œå›½",
    "EC": "ã‚¨ã‚¯ã‚¢ãƒ‰ãƒ«","EG": "ã‚¨ã‚¸ãƒ—ãƒˆ","SV": "ã‚¨ãƒ«ã‚µãƒ«ãƒãƒ‰ãƒ«","EE": "ã‚¨ã‚¹ãƒˆãƒ‹ã‚¢","ET": "ã‚¨ãƒã‚ªãƒ”ã‚¢","FI": "ãƒ•ã‚£ãƒ³ãƒ©ãƒ³ãƒ‰","FR": "ãƒ•ãƒ©ãƒ³ã‚¹","DE": "ãƒ‰ã‚¤ãƒ„",
    "GR": "ã‚®ãƒªã‚·ãƒ£","GL": "ã‚°ãƒªãƒ¼ãƒ³ãƒ©ãƒ³ãƒ‰","GT": "ã‚°ã‚¢ãƒ†ãƒãƒ©","GY": "ã‚¬ã‚¤ã‚¢ãƒŠ","HK": "é¦™æ¸¯","HU": "ãƒãƒ³ã‚¬ãƒªãƒ¼","IN": "ã‚¤ãƒ³ãƒ‰","ID": "ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢",
    "IR": "ã‚¤ãƒ©ãƒ³","IQ": "ã‚¤ãƒ©ã‚¯","IE": "ã‚¢ã‚¤ãƒ«ãƒ©ãƒ³ãƒ‰","IL": "ã‚¤ã‚¹ãƒ©ã‚¨ãƒ«","IT": "ã‚¤ã‚¿ãƒªã‚¢","JP": "æ—¥æœ¬","KR": "éŸ“å›½","TW": "å°æ¹¾","MY": "ãƒãƒ¬ãƒ¼ã‚·ã‚¢",
    "MX": "ãƒ¡ã‚­ã‚·ã‚³","NL": "ã‚ªãƒ©ãƒ³ãƒ€","NZ": "ãƒ‹ãƒ¥ãƒ¼ã‚¸ãƒ¼ãƒ©ãƒ³ãƒ‰","NO": "ãƒãƒ«ã‚¦ã‚§ãƒ¼","PK": "ãƒ‘ã‚­ã‚¹ã‚¿ãƒ³","PA": "ãƒ‘ãƒŠãƒ","PE": "ãƒšãƒ«ãƒ¼","PH": "ãƒ•ã‚£ãƒªãƒ”ãƒ³",
    "PL": "ãƒãƒ¼ãƒ©ãƒ³ãƒ‰","PT": "ãƒãƒ«ãƒˆã‚¬ãƒ«","QA": "ã‚«ã‚¿ãƒ¼ãƒ«","RO": "ãƒ«ãƒ¼ãƒãƒ‹ã‚¢","RU": "ãƒ­ã‚·ã‚¢","SA": "ã‚µã‚¦ã‚¸ã‚¢ãƒ©ãƒ“ã‚¢","SG": "ã‚·ãƒ³ã‚¬ãƒãƒ¼ãƒ«","ZA": "å—ã‚¢ãƒ•ãƒªã‚«",
    "ES": "ã‚¹ãƒšã‚¤ãƒ³","SE": "ã‚¹ã‚¦ã‚§ãƒ¼ãƒ‡ãƒ³","CH": "ã‚¹ã‚¤ã‚¹","TH": "ã‚¿ã‚¤","TR": "ãƒˆãƒ«ã‚³","UA": "ã‚¦ã‚¯ãƒ©ã‚¤ãƒŠ","AE": "ã‚¢ãƒ©ãƒ–é¦–é•·å›½é€£é‚¦","GB": "ã‚¤ã‚®ãƒªã‚¹",
    "US": "ã‚¢ãƒ¡ãƒªã‚«","VN": "ãƒ™ãƒˆãƒŠãƒ ","YE": "ã‚¤ã‚¨ãƒ¡ãƒ³","ZM": "ã‚¶ãƒ³ãƒ“ã‚¢","ZW": "ã‚¸ãƒ³ãƒãƒ–ã‚¨"
}

# --- ISPåç§°ã®æ—¥æœ¬èªãƒãƒƒãƒ”ãƒ³ã‚° (ä¼æ¥­åçµ±ä¸€ç‰ˆ) ---
ISP_JP_NAME = {
    # --- NTT Group ---
    'NTT Communications Corporation': 'NTTãƒ‰ã‚³ãƒ¢ãƒ“ã‚¸ãƒã‚¹', 
    'NTT COMMUNICATIONS CORPORATION': 'NTTãƒ‰ã‚³ãƒ¢ãƒ“ã‚¸ãƒã‚¹',
    'NTT DOCOMO BUSINESS,Inc.': 'NTTãƒ‰ã‚³ãƒ¢ãƒ“ã‚¸ãƒã‚¹',
    'NTT DOCOMO, INC.': 'NTTãƒ‰ã‚³ãƒ¢',
    'NTT PC Communications, Inc.': 'NTTPCã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚º',
    
    # --- KDDI Group ---
    'Kddi Corporation': 'KDDI',
    'KDDI CORPORATION': 'KDDI',
    'Chubu Telecommunications Co., Inc.': 'ä¸­éƒ¨ãƒ†ãƒ¬ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³',
    'Chubu Telecommunications Company, Inc.': 'ä¸­éƒ¨ãƒ†ãƒ¬ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³',
    'Hokkaido Telecommunication Network Co., Inc.': 'HOTnet',
    'Energia Communications, Inc.': 'ã‚¨ãƒã‚³ãƒ ',
    'STNet, Inc.': 'STNet',
    'QTNet, Inc.': 'QTNet',
    'BIGLOBE Inc.': 'ãƒ“ãƒƒã‚°ãƒ­ãƒ¼ãƒ–',
    
    # --- SoftBank Group ---
    'SoftBank Corp.': 'ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯',
    'Yahoo Japan Corporation': 'LINEãƒ¤ãƒ•ãƒ¼',
    'LY Corporation': 'LINEãƒ¤ãƒ•ãƒ¼',
    'LINE Corporation': 'LINEãƒ¤ãƒ•ãƒ¼',
    
    # --- Rakuten Group ---
    'Rakuten Group, Inc.': 'æ¥½å¤©ã‚°ãƒ«ãƒ¼ãƒ—',
    'Rakuten Mobile, Inc.': 'æ¥½å¤©ãƒ¢ãƒã‚¤ãƒ«',
    'Rakuten Communications Corp.': 'æ¥½å¤©ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚º',
    
    # --- Sony Group ---
    'Sony Network Communications Inc.': 'ã‚½ãƒ‹ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚º',
    'So-net Entertainment Corporation': 'ã‚½ãƒ‹ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚º', 
    'So-net Corporation': 'ã‚½ãƒ‹ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚º',
    
    # --- Major ISPs / VNEs ---
    'Internet Initiative Japan Inc.': 'IIJ',
    'NIFTY Corporation': 'ãƒ‹ãƒ•ãƒ†ã‚£',
    'FreeBit Co., Ltd.': 'ãƒ•ãƒªãƒ¼ãƒ“ãƒƒãƒˆ',
    'TOKAI Communications Corporation': 'TOKAIã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚º',
    'DREAM TRAIN INTERNET INC.': 'ãƒ‰ãƒªãƒ¼ãƒ ãƒ»ãƒˆãƒ¬ã‚¤ãƒ³ãƒ»ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ (DTI)',
    'ASAHI Net, Inc.': 'æœæ—¥ãƒãƒƒãƒˆ',
    'Asahi Net': 'æœæ—¥ãƒãƒƒãƒˆ',
    'Optage Inc.': 'ã‚ªãƒ—ãƒ†ãƒ¼ã‚¸',
    'Jupiter Telecommunications Co., Ltd.': 'J:COM', 
    'JCOM Co., Ltd.': 'J:COM',
    'JCN': 'J:COM', 
    'SAKURA Internet Inc.': 'ã•ãã‚‰ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ',
    'GMO Internet, Inc.': 'GMOã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ',
    'INTERNET MULTIFEED CO.': 'ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆãƒãƒ«ãƒãƒ•ã‚£ãƒ¼ãƒ‰',
    'IDC Frontier Inc.': 'IDCãƒ•ãƒ­ãƒ³ãƒ†ã‚£ã‚¢',
    
    # --- Others ---
    'ARTERIA Networks Corporation': 'ã‚¢ãƒ«ãƒ†ãƒªã‚¢ãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹',
    'UCOM Corporation': 'ã‚¢ãƒ«ãƒ†ãƒªã‚¢ãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹',
    'VECTANT Ltd.': 'ã‚¢ãƒ«ãƒ†ãƒªã‚¢ãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹',
    'KIBI Cable Television Co., Ltd.': 'å‰å‚™ã‚±ãƒ¼ãƒ–ãƒ«ãƒ†ãƒ¬ãƒ“',
}

# ğŸ†• å¼·åŠ›ãªåå¯„ã›ãƒ«ãƒ¼ãƒ« (éƒ¨åˆ†ä¸€è‡´æ¤œç´¢)
ISP_REMAP_RULES = [
    ('jcn', 'J:COM'), ('jupiter', 'J:COM'), ('cablenet', 'J:COM'),
    ('dion', 'KDDI'), ('au one', 'KDDI'), ('kddi', 'KDDI'),
    ('k-opti', 'ã‚ªãƒ—ãƒ†ãƒ¼ã‚¸'), ('ctc', 'ä¸­éƒ¨ãƒ†ãƒ¬ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³'),
    ('vectant', 'ã‚¢ãƒ«ãƒ†ãƒªã‚¢ãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹'), ('arteria', 'ã‚¢ãƒ«ãƒ†ãƒªã‚¢ãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¹'),
    ('softbank', 'ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯'), ('bbtec', 'ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯'),
    ('ocn', 'OCN'),
    ('so-net', 'ã‚½ãƒ‹ãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚º'), ('nuro', 'ã‚½ãƒ‹ãƒ¼ (NURO)'),
    ('biglobe', 'ãƒ“ãƒƒã‚°ãƒ­ãƒ¼ãƒ–'), ('iij', 'IIJ'),
    ('transix', 'ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆãƒãƒ«ãƒãƒ•ã‚£ãƒ¼ãƒ‰ (transix)'),
    ('v6plus', 'JPNE (v6ãƒ—ãƒ©ã‚¹)'),
    ('rakuten', 'æ¥½å¤©ã‚°ãƒ«ãƒ¼ãƒ—'),
]

def normalize_isp_key(text):
    if not text: return ""
    return text.lower().replace(',', '').replace('.', '').strip()

ISP_JP_NAME_NORMALIZED = {normalize_isp_key(k): v for k, v in ISP_JP_NAME.items()}

# --- åŒ¿ååŒ–ãƒ»ãƒ—ãƒ­ã‚­ã‚·åˆ¤å®šç”¨ãƒ‡ãƒ¼ã‚¿ ---

@st.cache_data(ttl=86400, show_spinner=False)
def fetch_tor_exit_nodes():
    try:
        url = "https://check.torproject.org/exit-addresses"
        response = requests.get(url, timeout=10)
        return set([line.split()[1] for line in response.text.splitlines() if line.startswith("ExitAddress")])
    except:
        return set()

HOSTING_VPN_KEYWORDS = [
    "hosting", "datacenter", "vps", "cloud", "server", "vpn", "proxy", "dedi",
    "amazon", "google", "microsoft", "azure", "oracle", "alibaba", "digitalocean", 
    "linode", "vultr", "ovh", "hetzner", "akamai", "cloudflare", "fastly",
    "expressvpn", "nordvpn", "proton", "mullvad", "cyberghost"
]

def detect_proxy_vpn_tor(ip, isp_name, tor_nodes):
    isp_lower = isp_name.lower()
    if ip in tor_nodes: return "Tor Node"
    if "icloud" in isp_lower or "private relay" in isp_lower: return "iCloud Private Relay"
    if any(kw in isp_lower for kw in ["vpn", "proxy"]): return "VPN/Proxy (Named)"
    if any(kw in isp_lower for kw in HOSTING_VPN_KEYWORDS): return "Hosting/DataCenter"
    return "Standard Connection"

def get_jp_names(english_isp, country_code):
    if not english_isp:
        return "N/A", COUNTRY_JP_NAME.get(country_code, country_code)

    normalized_input = normalize_isp_key(english_isp)
    jp_isp = english_isp 

    if english_isp in ISP_JP_NAME:
        jp_isp = ISP_JP_NAME[english_isp]
    elif normalized_input in ISP_JP_NAME_NORMALIZED:
        jp_isp = ISP_JP_NAME_NORMALIZED[normalized_input]
    else:
        for keyword, mapped_name in ISP_REMAP_RULES:
            if keyword in normalized_input:
                jp_isp = mapped_name
                break
        
    jp_country = COUNTRY_JP_NAME.get(country_code, country_code)
    return jp_isp, jp_country

@st.cache_resource
def get_session():
    session = requests.Session()
    session.headers.update({"User-Agent": "WhoisBatchTool/2.4 (+RDAP)"})
    return session

session = get_session()

@st.cache_data
def get_world_map_data():
    try:
        world_geojson = alt.topo_feature('https://cdn.jsdelivr.net/npm/vega-datasets@v1.29.0/data/world-110m.json', 'countries')
        return world_geojson
    except:
        return None

WORLD_MAP_GEOJSON = get_world_map_data()


# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤ ---
def clean_ocr_error_chars(target):
    cleaned_target = target.replace('â…¡', '11').replace('I', '1').replace('l', '1').replace('|', '1').replace('O', '0').replace('o', '0')
    if ':' not in cleaned_target:
        cleaned_target = cleaned_target.replace('S', '5').replace('s', '5')
    return cleaned_target

def is_valid_ip(target):
    try:
        ipaddress.ip_address(target)
        return True
    except ValueError:
        return False

def is_ipv4(target):
    try:
        ipaddress.IPv4Address(target)
        return True
    except ValueError:
        return False

def ip_to_int(ip):
    try:
        if is_ipv4(ip):
            return struct.unpack("!I", socket.inet_aton(ip))[0]
        return 0
    except OSError:
        return 0

def get_cidr_block(ip, netmask_range=(8, 24)):
    try:
        ip_obj = ipaddress.ip_address(ip)
        if ip_obj.version == 4:
            netmask = netmask_range[1] 
            network = ipaddress.ip_network(f'{ip}/{netmask}', strict=False)
            return str(network)
        elif ip_obj.version == 6:
            netmask = 48
            network = ipaddress.ip_network(f'{ip}/{netmask}', strict=False)
            return str(network)
        return None
    except ValueError:
        return None

def get_authoritative_rir_link(ip, country_code):
    rir_name = COUNTRY_CODE_TO_RIR.get(country_code)
    if rir_name and rir_name in RIR_LINKS:
        encoded_ip = quote(ip, safe='')
        if rir_name in ['RIPE', 'ARIN']:
            link_url = RIR_LINKS[rir_name].format(ip=encoded_ip)
            return f"[{rir_name}]({link_url})"
        elif rir_name in ['JPNIC', 'APNIC', 'LACNIC', 'AFRINIC']:
            link_url = RIR_LINKS[rir_name]  
            return f"[{rir_name} (æ‰‹å‹•æ¤œç´¢)]({link_url})"
    return f"[Whois (æ±ç”¨æ¤œç´¢)]({RIR_LINKS.get('APNIC', 'https://wq.apnic.net/static/search.html')})"

def get_copy_target(ip_display):
    if not ip_display: return ""
    return str(ip_display).split(' - ')[0].split(' ')[0]

def create_secondary_links(target):
    encoded_target = quote(target, safe='')
    is_ip = is_valid_ip(target)
    
    # ğŸ”— ãƒªãƒ³ã‚¯å®šç¾©ç”¨è¾æ›¸
    links = {}

    if is_ip:
        if is_ipv4(target):
            # --- IPv4ç”¨ å³é¸ãƒªãƒ³ã‚¯ ---
            # VirusTotal: ç·åˆçš„ãªã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è©•ä¾¡
            links['VirusTotal'] = f'https://www.virustotal.com/gui/search/{encoded_target}'
            # Aguse: æ—¥æœ¬å›½å†…ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹è§£æãƒ»ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆãƒã‚§ãƒƒã‚¯ã«å¼·åŠ›
            links['Aguse'] = f'https://www.aguse.jp/?url={encoded_target}'
            # ipinfo.io: åœ°ç†ä½ç½®æƒ…å ±ã‚„ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°åˆ¤å®šã®è©³ç´°ç¢ºèª
            links['ipinfo.io'] = f'https://ipinfo.io/{encoded_target}'
            # IP2Proxy: ãƒ—ãƒ­ã‚­ã‚·ãƒ»VPNåˆ¤å®šã«ç‰¹åŒ–
            links['IP2Proxy'] = f'https://www.ip2proxy.com/{encoded_target}'
            # IP Location: åœ°å›³è¡¨ç¤ºã¨åŸºæœ¬çš„ãªä½ç½®æƒ…å ±
            links['IP Location'] = f'https://iplocation.io/ip/{encoded_target}'
        else:
            # --- IPv6ç”¨ å³é¸ãƒªãƒ³ã‚¯ ---
            # VirusTotal: IPv6å¯¾å¿œ
            links['VirusTotal'] = f'https://www.virustotal.com/gui/search/{encoded_target}'
            # ipinfo.io: IPv6å®Œå…¨å¯¾å¿œ
            links['ipinfo.io'] = f'https://ipinfo.io/{encoded_target}'
            # IP2Proxy: IPv6å¯¾å¿œ (ãƒ—ãƒ­ã‚­ã‚·åˆ¤å®š)
            links['IP2Proxy'] = f'https://www.ip2proxy.com/{encoded_target}'
            # IP Location: IPv6å¯¾å¿œ (ä½ç½®æƒ…å ±)
            links['IP Location'] = f'https://iplocation.io/ip/{encoded_target}'
            # DNS Checker: IPv6ã®Whoisä¼æ’­ç¢ºèªç”¨
            links['DNS Checker'] = f'https://dnschecker.org/ipv6-whois-lookup.php?query={encoded_target}'
    else:
        # --- ãƒ‰ãƒ¡ã‚¤ãƒ³ç”¨ å³é¸ãƒªãƒ³ã‚¯ ---
        links['VirusTotal'] = f'https://www.virustotal.com/gui/search/{encoded_target}'
        # Aguse: ã‚µãƒ¼ãƒãƒ¼è¨¼æ˜æ›¸ã‚„ãƒãƒ«ã‚¦ã‚§ã‚¢ãƒã‚§ãƒƒã‚¯
        links['Aguse'] = f'https://www.aguse.jp/?url={encoded_target}'
        # Whois.com: æ±ç”¨çš„ãªãƒ‰ãƒ¡ã‚¤ãƒ³ç™»éŒ²æƒ…å ±ç¢ºèª
        links['Whois.com'] = f'https://www.whois.com/whois/{encoded_target}'

    # 1. ã€å…±é€šãƒ»å¿…é ˆã€‘CP-WHOIS (æ‰‹å‹•æ¤œç´¢ç”¨)
    links['CP-WHOIS (æ‰‹å‹•)'] = 'https://doco.cph.jp/whoisweb.php'


    # HTMLç”Ÿæˆ
    link_html = ""
    for name, url in links.items():
        if url: 
            link_html += f"[{name}]({url}) | "
    
    return link_html.rstrip(' | ')

# ğŸ†• RDAPãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•° (å…¬å¼å°å¸³ã¸ã®ç…§ä¼š)
def fetch_rdap_data(ip):
    try:
        url = RDAP_BOOTSTRAP_URL.format(ip=ip)
        # RDAPã¯ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ãŸã‚ allow_redirects=True, Timeoutã¯çŸ­ã‚ã«
        response = session.get(url, timeout=4, allow_redirects=True)
        if response.status_code == 200:
            data = response.json()
            # æ±ç”¨çš„ãªRDAPãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰åå‰ã‚’æ¢ã™ (name, handle, remarks)
            network_name = data.get('name', '')
            if not network_name and 'handle' in data:
                network_name = data['handle']
            return network_name
    except:
        pass
    return None

# ğŸ†• Proãƒ¢ãƒ¼ãƒ‰ç”¨ APIå–å¾—é–¢æ•° (ipinfo.io)
def get_ip_details_pro(ip, token, tor_nodes):
    result = {
        'Target_IP': ip, 'ISP': 'N/A', 'ISP_JP': 'N/A', 'Country': 'N/A', 'Country_JP': 'N/A', 
        'CountryCode': 'N/A', 'RIR_Link': 'N/A', 'Secondary_Security_Links': 'N/A', 'Status': 'N/A',
        'RDAP': '' # RDAPåˆ—ç”¨
    }
    try:
        url = IPINFO_API_URL.format(ip=ip)
        headers = {"Authorization": f"Bearer {token}"}
        response = session.get(url, headers=headers, timeout=10)
        
        if response.status_code == 429:
             result['Status'] = 'Error: Rate Limit (Pro)'
             return result
        
        if response.status_code == 403 or response.status_code == 401:
             result['Status'] = 'Error: Invalid API Key'
             return result

        response.raise_for_status()
        data = response.json()
        
        org_raw = data.get('org', '')
        isp_name = re.sub(r'^AS\d+\s+', '', org_raw) if org_raw else 'N/A'
        
        result['ISP'] = isp_name
        result['CountryCode'] = data.get('country', 'N/A')
        result['Country'] = result['CountryCode']
        result['RIR_Link'] = get_authoritative_rir_link(ip, result['CountryCode'])
        result['Status'] = 'Success (Pro)'
        
        jp_isp, jp_country = get_jp_names(result['ISP'], result['CountryCode'])
        result['ISP_JP'] = jp_isp
        result['Country_JP'] = jp_country

        # ipinfoã®privacyãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ä½¿ç”¨
        privacy_data = data.get('privacy', {})
        if privacy_data:
            detected = []
            if privacy_data.get('vpn'): detected.append("VPN")
            if privacy_data.get('proxy'): detected.append("Proxy")
            if privacy_data.get('tor'): detected.append("Tor Node")
            if privacy_data.get('hosting'): detected.append("Hosting")
            result['Proxy_Type'] = ", ".join(detected) if detected else ""
        else:
            proxy_type = detect_proxy_vpn_tor(ip, result['ISP'], tor_nodes)
            is_anonymous = (proxy_type != "Standard Connection")
            result['Proxy_Type'] = f"{proxy_type}" if is_anonymous else ""

    except Exception as e:
        result['Status'] = f'Error: Pro API ({type(e).__name__})'
    
    result['Secondary_Security_Links'] = create_secondary_links(ip)
    return result

# --- APIé€šä¿¡é–¢æ•° (Main) ---
def get_ip_details_from_api(ip, cidr_cache_snapshot, delay_between_requests, rate_limit_wait_seconds, tor_nodes, use_rdap, api_key=None):
    
    # 1. Proãƒ¢ãƒ¼ãƒ‰ (APIã‚­ãƒ¼ã‚ã‚Š)
    if api_key:
        result = get_ip_details_pro(ip, api_key, tor_nodes)
        # RDAPã‚ªãƒ—ã‚·ãƒ§ãƒ³æœ‰åŠ¹æ™‚
        if use_rdap:
            rdap_res = fetch_rdap_data(ip)
            if rdap_res:
                result['ISP'] += f" [RDAP: {rdap_res}]"
                result['RDAP'] = rdap_res # ğŸ†• RDAPåˆ—ã«å€¤ã‚’ã‚»ãƒƒãƒˆ
        return result, None

    # 2. é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ (ip-api.com)
    result = {
        'Target_IP': ip, 'ISP': 'N/A', 'ISP_JP': 'N/A', 'Country': 'N/A', 'Country_JP': 'N/A', 
        'CountryCode': 'N/A', 'RIR_Link': 'N/A', 'Secondary_Security_Links': 'N/A', 'Status': 'N/A',
        'RDAP': '' # RDAPåˆ—ç”¨
    }
    new_cache_entry = None

    cidr_block = get_cidr_block(ip)
    
    if cidr_block and cidr_block in cidr_cache_snapshot:
        cached_data = cidr_cache_snapshot[cidr_block]
        if time.time() - cached_data['Timestamp'] < 86400:
            result['ISP'] = cached_data['ISP']
            result['Country'] = cached_data['Country']
            result['CountryCode'] = cached_data['CountryCode']
            result['Status'] = "Success (Cache)" 
            jp_isp, jp_country = get_jp_names(result['ISP'], result['CountryCode'])
            proxy_type = detect_proxy_vpn_tor(ip, result['ISP'], tor_nodes)
            is_anonymous = (proxy_type != "Standard Connection")
            result['ISP_JP'] = jp_isp
            result['Proxy_Type'] = f"{proxy_type}" if is_anonymous else ""
            result['Country_JP'] = jp_country
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆæ™‚ã¯RDAPå†å–å¾—ã—ãªã„ï¼ˆé…ããªã‚‹ãŸã‚ï¼‰ã‹ã€å¿…è¦ãªã‚‰ã“ã“ã§å–å¾—
            return result, None 

    try:
        time.sleep(delay_between_requests) 

        url = IP_API_URL.format(ip=ip)
        response = session.get(url, timeout=45)
        
        if response.status_code == 429:
            defer_until = time.time() + rate_limit_wait_seconds
            result['Status'] = 'Error: Rate Limit (429)'
            result['Defer_Until'] = defer_until
            result['Secondary_Security_Links'] = create_secondary_links(ip)
            return result, new_cache_entry 
        
        response.raise_for_status()
        data = response.json()
        
        if data.get('status') == 'success':
            country_code = data.get('countryCode', 'N/A') 
            
            raw_isp = data.get('isp', 'N/A')
            raw_org = data.get('org', '')
            combined_name = raw_isp if raw_org == raw_isp else f"{raw_isp} / {raw_org}"
            
            result['ISP'] = combined_name
            result['Country'] = data.get('country', 'N/A')
            result['CountryCode'] = country_code
            result['RIR_Link'] = get_authoritative_rir_link(ip, country_code)
            
            # ğŸ†• RDAPå–å¾—ãƒ­ã‚¸ãƒƒã‚¯
            if use_rdap:
                rdap_res = fetch_rdap_data(ip)
                if rdap_res:
                    result['ISP'] += f" [RDAP: {rdap_res}]"
                    result['RDAP'] = rdap_res # ğŸ†• RDAPåˆ—ã«å€¤ã‚’ã‚»ãƒƒãƒˆ

            result['Status'] = 'Success (API)'
            
            jp_isp, jp_country = get_jp_names(result['ISP'], country_code)
            proxy_type = detect_proxy_vpn_tor(ip, result['ISP'], tor_nodes)
            is_anonymous = (proxy_type != "Standard Connection")
            result['ISP_JP'] = jp_isp
            result['Proxy_Type'] = f"{proxy_type}" if is_anonymous else ""
            result['Country_JP'] = jp_country
            
            if cidr_block:
                new_cache_entry = {
                    cidr_block: {
                    'ISP': result['ISP'], 
                    'Country': result['Country'],
                    'CountryCode': result['CountryCode'],
                    'Timestamp': time.time()
                    }
                }
            
        elif data.get('status') == 'fail':
            result['Status'] = f"API Fail: {data.get('message', 'Unknown Fail')}"
            result['RIR_Link'] = get_authoritative_rir_link(ip, 'N/A')
            
        else:
            result['Status'] = f"API Error: Unknown Response"
            result['RIR_Link'] = get_authoritative_rir_link(ip, 'N/A')
            
    except requests.exceptions.RequestException as e:
        result['Status'] = f'Error: Network/Timeout ({type(e).__name__})'
        
    result['Secondary_Security_Links'] = create_secondary_links(ip)
    return result, new_cache_entry

def get_domain_details(domain):
    icann_link = f"[ICANN Whois (æ‰‹å‹•æ¤œç´¢)]({RIR_LINKS['ICANN Whois']})"
    return {
        'Target_IP': domain, 'ISP': 'Domain/Host', 'Country': 'N/A', 'CountryCode': 'N/A',
        'RIR_Link': icann_link,
        'Secondary_Security_Links': create_secondary_links(domain),
        'Status': 'Success (Domain)',
        'RDAP': ''
    }

def get_simple_mode_details(target):
    if is_valid_ip(target):
        rir_link_content = f"[Whois (æ±ç”¨æ¤œç´¢ - APNICçª“å£)]({RIR_LINKS['APNIC']})"
    else:
        rir_link_content = f"[ICANN Whois (æ‰‹å‹•æ¤œç´¢)]({RIR_LINKS['ICANN Whois']})"
        
    return {
        'Target_IP': target, 
        'ISP': 'N/A (ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰)', 
        'Country': 'N/A (ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰)',
        'CountryCode': 'N/A',
        'RIR_Link': rir_link_content,
        'Secondary_Security_Links': create_secondary_links(target),
        'Status': 'Success (ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰)',
        'RDAP': ''
    }
# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤ ---

def group_results_by_isp(results):
    grouped = {}
    final_grouped_results = []
    non_aggregated_results = []
    successful_results = [res for res in results if res['Status'].startswith('Success')]

    for res in successful_results:
        is_ip = is_valid_ip(res['Target_IP'])
        if not is_ip or not is_ipv4(res['Target_IP']) or res['ISP'] == 'N/A' or res['Country'] == 'N/A' or res['ISP'] == 'N/A (ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰)':
            if res['Status'].startswith('Success (IPv4 CIDR Cache)'):
                non_aggregated_results.append(res)
            else:
                non_aggregated_results.append(res)
            continue
        
        key = (res['ISP'], res['CountryCode']) 
        
        if key not in grouped:
            grouped[key] = {
                'IP_Ints': [], 'IPs_List': [], 'RIR_Link': res['RIR_Link'],
                'Secondary_Security_Links': res['Secondary_Security_Links'],
                'ISP': res['ISP'], 
                'Country': res['Country'], 
                'Status': res['Status'],
                'ISP_JP': res.get('ISP_JP', 'N/A'),
                'Country_JP': res.get('Country_JP', 'N/A')
            }
        ip_int = ip_to_int(res['Target_IP'])
        if ip_int != 0:
            grouped[key]['IP_Ints'].append(ip_int)
            grouped[key]['IPs_List'].append(res['Target_IP'])
        else:
            res['Status'] = 'Error: IPv4 Int Conversion Failed'
            non_aggregated_results.append(res)

    non_aggregated_results.extend([res for res in results if not res['Status'].startswith('Success')])
    
    for key, data in grouped.items():
        if not data['IP_Ints']: 
            continue
            
        sorted_ip_ints = sorted(data['IP_Ints'])
        min_int = sorted_ip_ints[0]
        max_int = sorted_ip_ints[-1]
        count = len(data['IPs_List'])
        try:
            min_ip = str(ipaddress.IPv4Address(min_int))
            max_ip = str(ipaddress.IPv4Address(max_int))
        except ValueError:
            min_ip = data['IPs_List'][0]
            max_ip = data['IPs_List'][-1]
        
        target_ip_display = min_ip if count == 1 else f"{min_ip} - {max_ip} (x{count} IPs)"
        status_display = data['Status'] if count == 1 else f"Aggregated ({count} IPs)"
        
        final_grouped_results.append({
            'Target_IP': target_ip_display, 
            'Country': data['Country'], 
            'Country_JP': data['Country_JP'], 
            'ISP': data['ISP'],
            'ISP_JP': data['ISP_JP'], 
            'RIR_Link': data['RIR_Link'], 
            'Secondary_Security_Links': data['Secondary_Security_Links'],
            'Status': status_display
        })
    
    final_grouped_results.extend(non_aggregated_results)

    return final_grouped_results

# --- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é›†è¨ˆé–¢æ•° ---
def summarize_in_realtime(raw_results):
    isp_counts = {}
    country_counts = {}
    country_code_counts = {}

    target_frequency = st.session_state.get('target_freq_map', {})

    st.session_state['debug_summary'] = {} 

    country_all_df_raw = pd.DataFrame({
        'NumericCode': pd.Series(dtype='int64'), 
        'Count': pd.Series(dtype='int64'),
        'Country': pd.Series(dtype='str')
    })

    success_ipv4 = [
        r for r in raw_results 
        if r['Status'].startswith('Success') and is_ipv4(r['Target_IP'])
    ]

    for r in success_ipv4:
        ip = r.get('Target_IP')
        frequency = target_frequency.get(ip, 1) 

        isp_name = r.get('ISP_JP', r.get('ISP', 'N/A'))
        country_name = r.get('Country_JP', r.get('Country', 'N/A'))
        cc = r.get('CountryCode', 'N/A')
        
        if isp_name and isp_name not in ['N/A', 'N/A (ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰)']:
            isp_counts[isp_name] = isp_counts.get(isp_name, 0) + frequency
        
        if country_name and country_name != 'N/A':
            country_counts[country_name] = country_counts.get(country_name, 0) + frequency
            
        if cc and cc != 'N/A':
            country_code_counts[cc] = country_code_counts.get(cc, 0) + frequency

    # --- ISPé›†è¨ˆ ---
    isp_full_df = pd.DataFrame(list(isp_counts.items()), columns=['ISP', 'Count'])
    isp_full_df = isp_full_df.sort_values('Count', ascending=False)
    
    if not isp_full_df.empty:
        isp_df = isp_full_df.head(10).copy()
        isp_df['ISP'] = isp_df['ISP'].str.wrap(25)
    else:
        isp_df = pd.DataFrame(columns=['ISP', 'Count'])

    # --- å›½é›†è¨ˆ ---
    country_full_df = pd.DataFrame(list(country_counts.items()), columns=['Country', 'Count'])
    country_full_df = country_full_df.sort_values('Count', ascending=False)

    if not country_full_df.empty:
        country_df = country_full_df.head(10).copy()
        country_df['Country'] = country_df['Country'].str.wrap(25)
    else:
        country_df = pd.DataFrame(columns=['Country', 'Count'])

    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨
    if country_code_counts:
        map_data = []
        for cc, cnt in country_code_counts.items():
            num = COUNTRY_CODE_TO_NUMERIC_ISO.get(cc)
            if num is not None:
                name_for_map = COUNTRY_JP_NAME.get(cc, cc)
                map_data.append({
                    'NumericCode': int(num), 
                    'Count': int(cnt),
                    'Country': name_for_map
                })

        country_all_df_raw = pd.DataFrame(map_data).astype({
            'NumericCode': 'int64',
            'Count': 'int64'
        })
        
    st.session_state['debug_summary']['country_code_counts'] = country_code_counts
    st.session_state['debug_summary']['country_all_df'] = country_all_df_raw.to_dict('records')

    # --- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé »åº¦é›†è¨ˆ ---
    freq_map = st.session_state.get('target_freq_map', {})
    finished = st.session_state.get('finished_ips', set())
    freq_list = [{'Target_IP': t, 'Count': c} for t, c in freq_map.items() if t in finished]
    
    if freq_list:
        freq_full_df = pd.DataFrame(freq_list).sort_values('Count', ascending=False)
    else:
        freq_full_df = pd.DataFrame(columns=['Target_IP', 'Count'])
    
    if not freq_full_df.empty:
        freq_df = freq_full_df.head(10).copy()
    else:
        freq_df = pd.DataFrame(columns=['Target_IP', 'Count'])

    return isp_df, country_df, freq_df, country_all_df_raw, isp_full_df, country_full_df, freq_full_df

# --- é›†è¨ˆçµæœæç”»ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def draw_summary_content(isp_summary_df, country_summary_df, target_frequency_df, country_all_df, title):
    st.subheader(title)
    
    st.markdown("#### ğŸŒ å›½åˆ¥ IP ã‚«ã‚¦ãƒ³ãƒˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
    if WORLD_MAP_GEOJSON and not country_all_df.empty:
        
        base = alt.Chart(WORLD_MAP_GEOJSON).mark_geoshape(
            stroke='black', 
            strokeWidth=0.1
        ).encode(
            color=alt.value("#f0f0f052"), 
        ).project(
            type='mercator',
            scale=80,
            translate=[500, 180]        
        ).properties(
            title='World Map IP Count Heatmap',
            width=2500, 
            height=400 
        )

        heatmap = alt.Chart(WORLD_MAP_GEOJSON).mark_geoshape(
            stroke='black', 
            strokeWidth=0.1
        ).encode(
            color=alt.Color('Count:Q',
                            scale=alt.Scale(
                                type='log', 
                                domainMin=1,
                                domainMax=alt.Undefined,
                                range=['#99f6e4', '#facc15', '#dc2626']
                            ),
                            legend=alt.Legend(title="IP Count")),
            tooltip=[
                alt.Tooltip('Country:N', title='Country'),
                alt.Tooltip('Count:Q', title='IP Count', format=',')
            ]
        ).transform_lookup(
            lookup='id',
            from_=alt.LookupData(
                country_all_df, 
                key='NumericCode',          
                fields=['Count', 'Country']
            )
        ).project(
            type='mercator',
            scale=80,
            translate=[500, 180]
            )

        chart = alt.layer(base, heatmap).resolve_scale(
            color='independent'
        ).configure_legend(
            orient='right'
        ).interactive()
        
        st.altair_chart(chart, use_container_width=True)
        
    else:
        st.info("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯GeoJSONãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ã‹ã€æˆåŠŸã—ãŸIPv4ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„ãŸã‚è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
    
    st.markdown("---")


    col_freq, col_isp, col_country = st.columns([1, 1, 1]) 

    # å…±é€šãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆé–¢æ•°
    def create_labeled_bar_chart(df, x_field, y_field, title):
        base = alt.Chart(df).encode(
            x=alt.X(x_field, title='Count'),
            y=alt.Y(y_field, sort='-x', title=y_field),
            tooltip=[y_field, x_field]
        )
        bars = base.mark_bar()
        text = base.mark_text(
            align='left',
            baseline='middle',
            dx=3 
        ).encode(
            text=x_field
        )
        return (bars + text).properties(title=title).interactive()

    with col_freq:
        st.markdown("#### ğŸ¯ å¯¾è±¡IPåˆ¥ã‚«ã‚¦ãƒ³ãƒˆ (ãƒˆãƒƒãƒ—10)")
        if not target_frequency_df.empty:
            st.caption(f"**é›†è¨ˆå¯¾è±¡ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ•° (é‡è¤‡ãªã—):** {len(target_frequency_df)} ä»¶")
            chart = create_labeled_bar_chart(target_frequency_df, 'Count', 'Target_IP', 'Target IP Counts')
            st.altair_chart(chart, use_container_width=True)

            target_frequency_df_display = target_frequency_df.copy()
            target_frequency_df_display['Target_IP'] = target_frequency_df_display['Target_IP'].str.wrap(25)
            st.dataframe(target_frequency_df_display, hide_index=True, use_container_width=True)
        else:
            st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            
    with col_isp:
        st.markdown("#### ğŸ¢ ISPåˆ¥ã‚«ã‚¦ãƒ³ãƒˆ (ãƒˆãƒƒãƒ—10)")
        if not isp_summary_df.empty:
            chart = create_labeled_bar_chart(isp_summary_df, 'Count', 'ISP', 'ISP Counts')
            st.altair_chart(chart, use_container_width=True)
            
            st.dataframe(isp_summary_df, hide_index=True, use_container_width=True)
        else:
            st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            
    with col_country:
        st.markdown("#### ğŸŒ å›½åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ (ãƒˆãƒƒãƒ—10)")
        if not country_summary_df.empty:
            chart = create_labeled_bar_chart(country_summary_df, 'Count', 'Country', 'Country Counts')
            st.altair_chart(chart, use_container_width=True)
            
            st.dataframe(country_summary_df, hide_index=True, use_container_width=True)
        else:
            st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

# ğŸ’¡ HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–¢æ•°
def generate_full_report_html(isp_full_df, country_full_df, freq_full_df):
    
    def create_chunked_chart_specs(df, x_col, y_col, title_base, chunk_size=50):
        specs = []
        # ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã§ã®æœ€å¤§å€¤ã‚’å–å¾— (ãƒšãƒ¼ã‚¸ã¾ãŸãã®ã‚¹ã‚±ãƒ¼ãƒ«çµ±ä¸€ã®ãŸã‚)
        global_max = df[x_col].max() if not df.empty else 0

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åˆ†å‰²
        chunks = [df[i:i + chunk_size] for i in range(0, df.shape[0], chunk_size)]
        
        for i, chunk in enumerate(chunks):
            chart_title = f"{title_base} ({i+1}/{len(chunks)})" if len(chunks) > 1 else title_base
            
            # æ•°å€¤ãƒ©ãƒ™ãƒ«ä»˜ããƒãƒ£ãƒ¼ãƒˆ
            # ğŸ’¡ xè»¸ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’å…¨ä½“æœ€å¤§å€¤ã§å›ºå®šã™ã‚‹
            base = alt.Chart(chunk).encode(
                x=alt.X(x_col, title='Count', scale=alt.Scale(domain=[0, global_max])),
                y=alt.Y(y_col, sort='-x', title=y_col),
                tooltip=[y_col, x_col]
            )
            bars = base.mark_bar()
            text = base.mark_text(
                align='left',
                baseline='middle',
                dx=5, 
                fontSize=11,
                fontWeight='bold'
            ).encode(
                text=x_col
            )
            chart = (bars + text).properties(
                title=chart_title,
                width=700,
                height=alt.Step(20) 
            )
            specs.append(chart.to_dict())
        return specs

    # å„ã‚«ãƒ†ã‚´ãƒªã®ãƒãƒ£ãƒ¼ãƒˆã‚¹ãƒšãƒƒã‚¯ã‚’ç”Ÿæˆ
    target_specs = create_chunked_chart_specs(freq_full_df, 'Count', 'Target_IP', 'Target IP Counts (All)')
    isp_specs = create_chunked_chart_specs(isp_full_df, 'Count', 'ISP', 'ISP Counts (All)')
    country_specs = create_chunked_chart_specs(country_full_df, 'Count', 'Country', 'Country Counts (All)')

    # HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    html_template = f"""
    <!DOCTYPE html>
    <html>
    <head>
      <title>Whois Search Full Report</title>
      <script src="https://cdn.jsdelivr.net/npm/vega@5"></script>
      <script src="https://cdn.jsdelivr.net/npm/vega-lite@5"></script>
      <script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script>
      <style>
        body {{ font-family: "Helvetica Neue", Arial, sans-serif; padding: 40px; background-color: #fff; color: #333; }}
        h1 {{ text-align: center; border-bottom: 2px solid #333; padding-bottom: 10px; margin-bottom: 30px; }}
        h2 {{ 
            color: #1e3a8a; 
            margin-top: 50px; 
            border-left: 5px solid #1e3a8a; 
            padding-left: 15px; 
            page-break-before: always; 
        }}
        h2:first-of-type {{ page-break-before: auto; }} 
        
        .chart-container {{ 
            margin-bottom: 40px; 
            padding: 10px; 
            page-break-inside: avoid; 
        }}
        
        @media print {{
            body {{ padding: 0; background-color: #fff; }}
            .no-print {{ display: none; }}
            h2 {{ margin-top: 20px; }}
        }}
      </style>
    </head>
    <body>
      <h1>Whoisæ¤œç´¢çµæœåˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>
      <p style="text-align: center; color: #666;">Generated by Whois Search Tool</p>

      <h2>å¯¾è±¡IPã‚¢ãƒ‰ãƒ¬ã‚¹ ã‚«ã‚¦ãƒ³ãƒˆ (å…¨ {len(freq_full_df)} ä»¶)</h2>
      <div id="target_charts"></div>

      <h2>ISPåˆ¥ ã‚«ã‚¦ãƒ³ãƒˆ (å…¨ {len(isp_full_df)} ä»¶)</h2>
      <div id="isp_charts"></div>

      <h2>å›½åˆ¥ ã‚«ã‚¦ãƒ³ãƒˆ (å…¨ {len(country_full_df)} ä»¶)</h2>
      <div id="country_charts"></div>

      <script type="text/javascript">
        // Embed charts function
        function embedCharts(containerId, specs) {{
            const container = document.getElementById(containerId);
            specs.forEach((spec, index) => {{
                const div = document.createElement('div');
                div.id = containerId + '_' + index;
                div.className = 'chart-container';
                container.appendChild(div);
                vegaEmbed('#' + div.id, spec, {{actions: false}});
            }});
        }}

        // Data from Python (Serialized to JSON)
        const targetSpecs = {json.dumps(target_specs)};
        const ispSpecs = {json.dumps(isp_specs)};
        const countrySpecs = {json.dumps(country_specs)};

        // Render
        if (targetSpecs.length > 0) embedCharts('target_charts', targetSpecs);
        else document.getElementById('target_charts').innerHTML = '<p>ãƒ‡ãƒ¼ã‚¿ãªã—</p>';

        if (ispSpecs.length > 0) embedCharts('isp_charts', ispSpecs);
        else document.getElementById('isp_charts').innerHTML = '<p>ãƒ‡ãƒ¼ã‚¿ãªã—</p>';

        if (countrySpecs.length > 0) embedCharts('country_charts', countrySpecs);
        else document.getElementById('country_charts').innerHTML = '<p>ãƒ‡ãƒ¼ã‚¿ãªã—</p>';
      </script>
    </body>
    </html>
    """
    return html_template

# ğŸ“ˆ ã‚¯ãƒ­ã‚¹åˆ†æç”¨HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–¢æ•°
def generate_cross_analysis_html(chart_spec, x_col, group_col):
    html_template = f"""
    <!DOCTYPE html>
    <html>
    <head>
      <title>Whois Cross Analysis Report</title>
      <script src="https://cdn.jsdelivr.net/npm/vega@5"></script>
      <script src="https://cdn.jsdelivr.net/npm/vega-lite@5"></script>
      <script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script>
      <style>
        body {{ font-family: "Helvetica Neue", Arial, sans-serif; padding: 40px; background-color: #fff; color: #333; }}
        h1 {{ text-align: center; border-bottom: 2px solid #333; padding-bottom: 10px; margin-bottom: 30px; }}
        .info {{ text-align: center; color: #666; margin-bottom: 20px; }}
        .chart-container {{ 
            width: 100%; 
            display: flex; 
            justify-content: center; 
            margin-bottom: 40px; 
            padding: 10px; 
        }}
      </style>
    </head>
    <body>
      <h1>ã‚¯ãƒ­ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ: {x_col} vs {group_col}</h1>
      <p class="info">Generated by Whois Search Tool</p>

      <div id="chart" class="chart-container"></div>

      <script type="text/javascript">
        const spec = {json.dumps(chart_spec)};
        vegaEmbed('#chart', spec, {{actions: true}});
      </script>
    </body>
    </html>
    """
    return html_template

# --- Excelç”Ÿæˆãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def convert_df_to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    return output.getvalue()

# --- Advanced Excel Generator (Pivot & Chart) ---
def create_advanced_excel(df, time_col_name=None):
    """
    1. Raw Data
    2. Report_ISP_Volume: ISP Ranking (Bar Chart)
    3. Report_ISP_Risk: ISP x ProxyType (Stacked Bar)
    4. Report_Time_Volume: Hour Trend (Bar/Line) [if time_col available]
    5. Report_Time_Risk: Hour x ProxyType (Stacked Bar) [if time_col available]
    """
    output = io.BytesIO()
    
    # 1. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    if 'Proxy Type' in df.columns:
        df['Proxy Type'] = df['Proxy Type'].fillna('Standard Connection')
        df['Proxy Type'] = df['Proxy Type'].replace('', 'Standard Connection')
        # å¤ã„ç”¨èªãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆã®å¿µã®ç‚ºã®ç½®æ›
        df['Proxy Type'] = df['Proxy Type'].replace('Residential/Normal', 'Standard Connection')
        df['Proxy Type'] = df['Proxy Type'].replace('Residential/General', 'Standard Connection')
        df['Proxy Type'] = df['Proxy Type'].replace('Residential/Business', 'Standard Connection')
        df['Proxy Type'] = df['Proxy Type'].replace('nan', 'Standard Connection')
    else:
        df['Proxy Type'] = 'Standard Connection'
    
    # æ™‚é–“å¸¯åˆ—ã®ä½œæˆ
    has_time_analysis = False
    if time_col_name and time_col_name in df.columns:
        try:
            df['Hour'] = pd.to_datetime(df[time_col_name], errors='coerce').dt.hour
            has_time_analysis = True
        except Exception:
            pass

    # ã‚«ã‚¦ãƒ³ãƒˆç”¨ã®åˆ—ï¼ˆæœ€åˆã®åˆ—ã‚’ä½¿ã†ï¼‰
    count_col = df.columns[0]

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # Sheet 1: Raw Data
        df.to_excel(writer, index=False, sheet_name='Raw Data')
        wb = writer.book
        
        # --- å…±é€šãƒãƒ£ãƒ¼ãƒˆä½œæˆé–¢æ•° (è§£èª¬æ–‡ä»˜ã) ---
        def add_chart_sheet(pivot_df, sheet_name, chart_title, x_title, y_title, description, chart_type="col", stacked=False):
            if pivot_df.empty: return

            # Sheetä½œæˆã¨ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ (ãƒ˜ãƒƒãƒ€ãƒ¼ç”¨ã«å°‘ã—ä¸‹ã’ã‚‹)
            pivot_df.to_excel(writer, sheet_name=sheet_name, startrow=4)
            ws = wb[sheet_name]
            
            # --- è§£èª¬æ–‡ã®æŒ¿å…¥ ---
            ws['A1'] = chart_title
            ws['A1'].font = Font(size=14, bold=True, color="1E3A8A")
            
            ws['A2'] = description
            ws['A2'].font = Font(size=11, color="555555", italic=True)
            ws['A2'].alignment = Alignment(wrap_text=True, vertical="top")
            
            # ã‚»ãƒ«çµåˆ (èª¬æ˜æ–‡ã‚¨ãƒªã‚¢)
            ws.merge_cells('A2:H3')
            
            # å°åˆ·è¨­å®šï¼ˆæ¨ªå‘ãï¼‰
            ws.page_setup.orientation = ws.ORIENTATION_LANDSCAPE
            ws.page_setup.fitToWidth = 1
            ws.print_options.horizontalCentered = True
            
            # --- ã‚°ãƒ©ãƒ•ä½œæˆ  ---
            chart = BarChart()
            chart.type = chart_type
            chart.style = 10 # ã‚«ãƒ©ãƒ•ãƒ«ãªã‚¹ã‚¿ã‚¤ãƒ«
            chart.title = chart_title
            chart.height = 15 # é«˜ã•ã‚’ç¢ºä¿
            chart.width = 25  # å¹…ã‚’ç¢ºä¿

            # å‡¡ä¾‹ã‚’ä¸‹ã«é…ç½®
            chart.legend.position = 'b'

            if stacked:
                chart.grouping = "stacked"
                chart.overlap = 100
            else:
                # ç©ã¿ä¸Šã’ã§ãªã„å ´åˆã¯ã€å˜ä¸€ç³»åˆ—ã§ã‚‚è‰²ã‚’å¤‰ãˆã¦è¦‹ã‚„ã™ãã™ã‚‹
                chart.varyColors = True

            # ãƒ‡ãƒ¼ã‚¿ãƒ©ãƒ™ãƒ«ã®è¨­å®š (å€¤ã‚’è¡¨ç¤º + ä½ç½®ã‚’å¤–å´ä¸Š 'outEnd' ã«)
            # â€» ç©ã¿ä¸Šã’ã®å ´åˆã¯å†…å´ã€ãã‚Œä»¥å¤–ã¯å¤–å´ãŒè¦‹ã‚„ã™ã„
            chart.dataLabels = DataLabelList()
            chart.dataLabels.showVal = True
            chart.dataLabels.showCatName = False
            chart.dataLabels.showSerName = False
            chart.dataLabels.showPercent = False
            if not stacked:
                chart.dataLabels.position = 'outEnd'
            
            # è»¸ã¨ç›®ç››ã‚Šç·šã®è¨­å®š
            chart.x_axis.title = x_title
            chart.y_axis.title = y_title
            chart.y_axis.majorGridlines = ChartLines() # ç›®ç››ã‚Šç·šã‚’è¡¨ç¤º
            
            # ç¸¦è»¸ã®ç›®ç››ãƒ©ãƒ™ãƒ«ï¼ˆæ•°å€¤ï¼‰ã‚’ç¢ºå®Ÿã«è¡¨ç¤ºãƒ»æ•´å½¢ã™ã‚‹è¨­å®š
            chart.y_axis.delete = False        
            chart.y_axis.numFmt = '0'          # æ•´æ•°è¡¨ç¤º
            chart.y_axis.majorTickMark = 'out' # ç›®ç››ã‚Šã‚’å¤–å´ã«å‡ºã™
            chart.y_axis.tickLblPos = 'nextTo' # æ•°å€¤ã‚’è»¸ã®éš£ã«é…ç½®

            # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’æ‰‹å‹•è¨­å®šã—ã¦ä½™ç™½ã‚’ä½œã‚‹ (é‡ãªã‚Šé˜²æ­¢ + ã‚¹ã‚«ã‚¹ã‚«è§£æ¶ˆ)
            # x=0.03 (å·¦å¯„ã›), y=0.05 (ä¸Šä½™ç™½), h=0.75 (é«˜ã•ç¢ºä¿), w=0.85 (å³ä½™ç™½ç¢ºä¿)
            chart.layout = Layout(
                manualLayout=ManualLayout(
                    x=0.03, y=0.05, 
                    h=0.75, w=0.85, 
                )
            )

            # ãƒ‡ãƒ¼ã‚¿ç¯„å›²è¨­å®š
            data_start_row = 5 
            data_end_row = data_start_row + len(pivot_df)
            
            data = Reference(ws, min_col=2, min_row=data_start_row, max_row=data_end_row, max_col=len(pivot_df.columns)+1)
            cats = Reference(ws, min_col=1, min_row=data_start_row+1, max_row=data_end_row)
            
            chart.add_data(data, titles_from_data=True)
            chart.set_categories(cats)
            
            # ã‚°ãƒ©ãƒ•é…ç½® (ãƒ‡ãƒ¼ã‚¿ã®ä¸‹ã§ã¯ãªãæ¨ªã«é…ç½®ã—ã¦è¦‹ã‚„ã™ã)
            ws.add_chart(chart, "E5")

        # ---------------------------------------------------------
        # 2. Report_ISP_Volume: [ISP_JP] x [Count]
        # ---------------------------------------------------------
        top_isps = df['ISP_JP'].value_counts().head(20).index
        df_isp = df[df['ISP_JP'].isin(top_isps)]
        pivot_isp_vol = df_isp.pivot_table(
            index='ISP_JP', 
            values=count_col, 
            aggfunc='count'
        ).sort_values(count_col, ascending=False)
        
        desc_isp_vol = "ã©ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæœ€ã‚‚å¤šã„ã‹ã‚’å¯è¦–åŒ–ã—ã¦ã„ã¾ã™ã€‚ç‰¹å®šã®ISPã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹é›†ä¸­ã¯ã€ãã®ã‚µãƒ¼ãƒ“ã‚¹ã®åˆ©ç”¨è€…å±¤ã¾ãŸã¯ç‰¹å®šã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®å½±éŸ¿ã‚’ç¤ºå”†ã—ã¾ã™ã€‚"
        add_chart_sheet(pivot_isp_vol, 'Report_ISP_Volume', 'ISP Access Volume Ranking (Top 20)', 'Internet Service Provider', 'Access Count (ä»¶æ•°)', desc_isp_vol)

        # ---------------------------------------------------------
        # 3. Report_ISP_Risk: [ISP_JP] x [Proxy Type]
        # ---------------------------------------------------------
        pivot_isp_risk = df_isp.pivot_table(
            index='ISP_JP', 
            columns='Proxy Type', 
            values=count_col, 
            aggfunc='count', 
            fill_value=0
        )
        desc_isp_risk = "ãã®ISPãŒå®‰å…¨ãªä¸€èˆ¬å›ç·šã‹ã€æ³¨æ„ãŒå¿…è¦ãªã‚µãƒ¼ãƒãƒ¼/VPNçµŒç”±ã‹ã‚’åˆ¤å®šã—ã¦ã„ã¾ã™ã€‚ã€ŒStandard Connectionã€ã¯ä¸€èˆ¬çš„ãªå®‰å…¨ãªæ¥ç¶šã§ã™ã€‚ã€ŒHostingã€ã‚„ã€ŒVPNã€ãŒå¤šã„å ´åˆã¯æ©Ÿæ¢°çš„ãªã‚¢ã‚¯ã‚»ã‚¹ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
        add_chart_sheet(pivot_isp_risk, 'Report_ISP_Risk', 'Risk Analysis by ISP (Top 20)', 'Internet Service Provider', 'Access Count (ä»¶æ•°)', desc_isp_risk, stacked=True)
        
        # ---------------------------------------------------------
        # 4. Report_Country: [Country_JP] x [Count] (Bonus)
        # ---------------------------------------------------------
        pivot_country = df.pivot_table(
            index='Country_JP',
            values=count_col,
            aggfunc='count'
        ).sort_values(count_col, ascending=False).head(15)
        desc_country = "å›½ã”ã¨ã®ã‚¢ã‚¯ã‚»ã‚¹æ•°ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŒ–ã—ã¦ã„ã¾ã™ã€‚ã‚µãƒ¼ãƒ“ã‚¹æä¾›ã‚¨ãƒªã‚¢å¤–ã‹ã‚‰ã®äºˆæœŸã›ã¬ã‚¢ã‚¯ã‚»ã‚¹æ¤œçŸ¥ã‚„ã€æµ·å¤–ã‹ã‚‰ã®æ”»æ’ƒäºˆå…†ã®ç™ºè¦‹ã«å½¹ç«‹ã¡ã¾ã™ã€‚"
        add_chart_sheet(pivot_country, 'Report_Country', 'Country Access Volume (Top 15)', 'Country Name', 'Access Count (ä»¶æ•°)', desc_country)

        # ---------------------------------------------------------
        # 5. Time Analysis (if available)
        # ---------------------------------------------------------
        if has_time_analysis:
            # Report_Time_Volume: [Hour] x [Count]
            pivot_time_vol = df.pivot_table(
                index='Hour',
                values=count_col,
                aggfunc='count',
                fill_value=0
            ).reindex(range(24), fill_value=0)
            desc_time_vol = "ä½•æ™‚ã«ã‚¢ã‚¯ã‚»ã‚¹ãŒé›†ä¸­ã—ã¦ã„ã‚‹ã‹ã‚’å¯è¦–åŒ–ã—ã¦ã„ã¾ã™ã€‚ä¸€èˆ¬çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ´»å‹•æ™‚é–“å¸¯ã«ã€Botãªã©ã¯æ·±å¤œæ—©æœã‚„24æ™‚é–“ä¸€å®šã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¡Œã†å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚"
            add_chart_sheet(pivot_time_vol, 'Report_Time_Volume', 'Hourly Access Trend', 'Time of Day (0-23h)', 'Access Count (ä»¶æ•°)', desc_time_vol)

            # Report_Time_Risk: [Hour] x [Proxy Type]
            pivot_time_risk = df.pivot_table(
                index='Hour',
                columns='Proxy Type',
                values=count_col,
                aggfunc='count',
                fill_value=0
            ).reindex(range(24), fill_value=0)
            desc_time_risk = "æ·±å¤œå¸¯ãªã©ã«æ€ªã—ã„ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆHosting/VPNç­‰ï¼‰ãŒå¢—ãˆã¦ã„ãªã„ã‹ã‚’ç¢ºèªã§ãã¾ã™ã€‚å¤œé–“ã«Hostingåˆ¤å®šãŒå¢—åŠ ã™ã‚‹å ´åˆã€Botã«ã‚ˆã‚‹è‡ªå‹•å·¡å›ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
            add_chart_sheet(pivot_time_risk, 'Report_Time_Risk', 'Hourly Risk Trend', 'Time of Day (0-23h)', 'Access Count (ä»¶æ•°)', desc_time_risk, stacked=True)
            
    return output.getvalue()

def display_results(results, current_mode_full_text, display_mode):
    st.markdown("### ğŸ“ æ¤œç´¢çµæœ")

    # --- â¬‡ï¸ ãƒ„ãƒ¼ãƒ«è§£èª¬ã‚¬ã‚¤ãƒ‰ (Expander) ---
    with st.expander("â„¹ï¸ ãƒªãƒ³ã‚¯é›†ã®æ´»ç”¨ã‚¬ã‚¤ãƒ‰ (è¡¨ç¤ºæ¡ä»¶ã¨ç‰¹å¾´)"):
        st.markdown("""
        ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ç¨®é¡ï¼ˆIPv4 / IPv6 / ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼‰ã«å¿œã˜ã¦ã€æœ€é©ãªãƒ„ãƒ¼ãƒ«ã®ã¿ãŒè‡ªå‹•ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
        
        | ç›®çš„ | æ¨å¥¨ãƒ„ãƒ¼ãƒ« | è¡¨ç¤ºæ¡ä»¶ | ç‰¹å¾´ |
        | :--- | :--- | :--- | :--- |
        | ğŸ›¡ï¸ **å®‰å…¨æ€§ã‚’è¨ºæ–­** | **VirusTotal** | `v4` `v6` `Dom` | ä¸–ç•Œä¸­ã®ã‚¦ã‚¤ãƒ«ã‚¹å¯¾ç­–ã‚¨ãƒ³ã‚¸ãƒ³ã§ä¸€æ‹¬ã‚¹ã‚­ãƒ£ãƒ³ã€‚å±é™ºãªIPã‹å³åº§ã«åˆ¤åˆ¥ã€‚ |
        | ğŸ‡¯ğŸ‡µ **å›½å†…èª¿æŸ»ãƒ»è©³ç´°** | **Aguse** | `v4` `Dom` | æ—¥æœ¬èªè¡¨ç¤ºã€‚ãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆåˆ¤å®šã‚„ã€ã‚µãƒ¼ãƒãƒ¼è¨¼æ˜æ›¸æƒ…å ±ãŒè¦‹ã‚„ã™ã„ã€‚ |
        | ğŸ“ **å ´æ‰€ãƒ»å›ç·šç‰¹å®š** | **ipinfo.io** | `v4` `v6` | åœ°å›³ä¸Šã®ä½ç½®ã€ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°(ã‚¯ãƒ©ã‚¦ãƒ‰)ã‹ã©ã†ã‹ã®è©³ç´°åˆ¤å®šã«å¼·ã„ã€‚ |
        | ğŸ•µï¸ **VPN/Proxyåˆ¤å®š** | **IP2Proxy** | `v4` `v6` | åŒ¿åãƒ—ãƒ­ã‚­ã‚·ã‚„VPNã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã‹ã©ã†ã‹ã‚’å°‚é–€çš„ã«åˆ¤å®šã€‚ |
        | ğŸ—ºï¸ **åœ°å›³è¡¨ç¤º** | **IP Location** | `v4` `v6` | IPã‚¢ãƒ‰ãƒ¬ã‚¹ã®åœ°ç†çš„ä½ç½®ã‚’Googleãƒãƒƒãƒ—ç­‰ã§è¦–è¦šçš„ã«è¡¨ç¤ºã€‚ |
        | ğŸ“ **ç™»éŒ²è€…æƒ…å ±** | **Whois.com** | `Dom` | ãƒ‰ãƒ¡ã‚¤ãƒ³ã®æ‰€æœ‰è€…æƒ…å ±ï¼ˆè‹±èªï¼‰ã‚’ç¢ºèªã™ã‚‹ã®ã«æœ€é©ã€‚IPæ¤œç´¢æ™‚ã¯éè¡¨ç¤ºã€‚ |
        | ğŸ“¡ **ä¼æ’­ç¢ºèª** | **DNS Checker** | `v6` | IPv6ã®Whoisæƒ…å ±ãŒä¸–ç•Œä¸­ã§ã©ã†è¦‹ãˆã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã€‚ |
        | ğŸ“š **å…¬å¼æƒ…å ±** | **CP-WHOIS** | `ALL` | åˆ©ç”¨è€…èªè¨¼ãŒå¿…è¦ãªæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã€‚ã“ã“ã§ã®æ¤œç´¢çµæœã¯ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿¡é ¼æ€§ãŒé«˜ã„ã€‚ |
        
        <small>â€» `v4`: IPv4ã‚¢ãƒ‰ãƒ¬ã‚¹, `v6`: IPv6ã‚¢ãƒ‰ãƒ¬ã‚¹, `Dom`: ãƒ‰ãƒ¡ã‚¤ãƒ³å, `ALL`: å…¨ã¦</small>
        """, unsafe_allow_html=True)
    # ----------------------------------------------------

    with st.expander("âš ï¸ åˆ¤å®šã‚¢ã‚¤ã‚³ãƒ³ã¨è¡¨ç¤ºãƒ«ãƒ¼ãƒ«ã«ã¤ã„ã¦"):
        st.info("""
        ### ğŸ” åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ã®æ¦‚è¦
        æœ¬ãƒ„ãƒ¼ãƒ«ã¯ã€IPã‚¢ãƒ‰ãƒ¬ã‚¹ã«ç´ä»˜ã‘ã‚‰ã‚ŒãŸ**ASNï¼ˆAutonomous System Numberï¼‰ãŠã‚ˆã³ISPï¼ˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆã‚µãƒ¼ãƒ“ã‚¹ãƒ—ãƒ­ãƒã‚¤ãƒ€ï¼‰ã®åç§°ãƒ»å±æ€§**ã‚’è§£æã—ã€é€šä¿¡ä¸»ä½“ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¨®åˆ¥ã‚’è‡ªå‹•çš„ã«åˆ†é¡ã—ã¦ã„ã¾ã™ã€‚
        
        ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆä¸Šã®é€šä¿¡ã¯ã€ãã®ç”¨é€”ã«å¿œã˜ã¦ã€Œå€‹äººå®…ãƒ»æ³•äººæ‹ ç‚¹ã‹ã‚‰ã®ç›´æ¥æ¥ç¶šã€ã¨ã€Œéå¯¾é¢çš„ãªä¸­ç¶™ãƒ»ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°çµŒç”±ã®æ¥ç¶šã€ã«å¤§åˆ¥ã•ã‚Œã¾ã™ã€‚æœ¬æ©Ÿèƒ½ã¯å¾Œè€…ã‚’æ¤œçŸ¥ã—ã€èª¿æŸ»ã®å„ªå…ˆé †ä½åˆ¤æ–­ã‚’æ”¯æ´ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚
        
        ---
        
        ### ğŸ“Œ åˆ¤å®šç¨®åˆ¥ã®å®šç¾©ã¨æŠ€è¡“çš„èƒŒæ™¯
        
        - **âš ï¸ [Tor Node]**
            - **å®šç¾©**: Torï¼ˆThe Onion Routerï¼‰ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ãŠã‘ã‚‹ã€ŒExit Nodeï¼ˆå‡ºå£ãƒãƒ¼ãƒ‰ï¼‰ã€ã‚’æŒ‡ã—ã¾ã™ã€‚
            - **èƒŒæ™¯**: èµ·å‹•æ™‚ã«Tor Projectå…¬å¼ã‚µã‚¤ãƒˆã‚ˆã‚Šæœ€æ–°ã®ãƒãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’å–å¾—ã—ã€ç…§åˆã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚é«˜ã„åŒ¿åæ€§ã‚’ç¶­æŒã—ãŸé€šä¿¡ã§ã‚ã‚‹ãŸã‚ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã®æ¤œè¨ãŒå¿…è¦ã§ã™ã€‚
            
        - **âš ï¸ [VPN/Proxy]**
            - **å®šç¾©**: å•†ç”¨VPNã‚µãƒ¼ãƒ“ã‚¹ã€å…¬é–‹ãƒ—ãƒ­ã‚­ã‚·ã€ã¾ãŸã¯ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ã‚’ç›®çš„ã¨ã—ãŸä¸­ç¶™å›£ä½“ã«å±ã™ã‚‹IPã§ã™ã€‚
            - **èƒŒæ™¯**: ISPåç§°ã«å«ã¾ã‚Œã‚‹ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆVPN, Proxyç­‰ï¼‰ãŠã‚ˆã³æ—¢çŸ¥ã®åŒ¿ååŒ–ã‚µãƒ¼ãƒ“ã‚¹é‹å–¶çµ„ç¹”åã«åŸºã¥ãåˆ¤åˆ¥ã—ã¾ã™ã€‚
            
        - **âš ï¸ [Hosting/Infra]**
            - **å®šç¾©**: ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ï¼ˆAWS, Azure, GCPç­‰ï¼‰ã‚„ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã€ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°äº‹æ¥­è€…ã®ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã§ã™ã€‚
            - **èƒŒæ™¯**: ä¸€èˆ¬çš„ãªã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒå›ç·šã¨ã¯ç•°ãªã‚Šã€ã‚µãƒ¼ãƒãƒ¼é–“é€šä¿¡ã‚„Botã€ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã€ã‚ã‚‹ã„ã¯æ”»æ’ƒç”¨ã‚¤ãƒ³ãƒ•ãƒ©ã¨ã—ã¦åˆ©ç”¨ã•ã‚Œã‚‹ã‚±ãƒ¼ã‚¹ãŒå¤šã„ãƒãƒ¼ãƒ‰ã§ã™ã€‚
            
        ---
        
        â€» æœ¬åˆ¤å®šã¯ISPåç§°ç­‰ã«åŸºã¥ãæ¨è«–ã§ã‚ã‚‹ãŸã‚ã€å®Ÿéš›ã®åˆ©ç”¨çŠ¶æ³ã¨ç•°ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
        """)
    
    col_widths = [0.5, 1.5, 1.2, 2.0, 1.5, 1.5, 1.0, 1.2, 0.5] 
    h_cols = st.columns(col_widths)
    headers = ["No.", "Target IP", "å›½å","ISP(æ—¥æœ¬èª)", "RIR Link", "Security Links", "Proxy Type",  "Status", "âœ…"]
    for col, name in zip(h_cols, headers):
        col.markdown(f"**{name}**")
    st.markdown("<hr style='margin: 0px 0px 10px 0px;'>", unsafe_allow_html=True)

    with st.container(height=800):
        if not results:
            st.info("æ¤œç´¢çµæœãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
            return

        for idx, res in enumerate(results):
                row_cols = st.columns(col_widths)
                row_cols[0].write(f"**{idx+1}**")
                
                target_ip = res.get('Target_IP', 'N/A')
                row_cols[1].markdown(f"`{target_ip}`")
                
                c_jp = res.get('Country_JP', 'N/A')
                c_en = res.get('Country', 'N/A')
                row_cols[2].write(f"{c_jp}\n({c_en})")
                
                isp_display = res.get('ISP_JP', res.get('ISP', 'N/A'))
                row_cols[3].write(isp_display)
                
                rir_link = res.get('RIR_Link', 'N/A')
                with row_cols[4]:
                    st.write(rir_link)
                    clean_ip = get_copy_target(target_ip)
                    st.code(clean_ip, language=None)
                
                row_cols[5].write(res.get('Secondary_Security_Links', 'N/A'))
                hosting_val = res.get('Proxy_Type', '')
                row_cols[6].write(hosting_val)          
                
                status_val = res.get('Status', 'N/A')
                if "Success" in status_val:
                    row_cols[7].markdown(f"<span style='color:green;'>{status_val}</span>", unsafe_allow_html=True)
                else:
                    row_cols[7].write(status_val)
                    
                row_cols[8].checkbox("é¸æŠ", key=f"chk_{get_copy_target(target_ip)}_{idx}", label_visibility="collapsed")

# ğŸ“Š å…ƒãƒ‡ãƒ¼ã‚¿çµåˆåˆ†ææ©Ÿèƒ½
def render_merged_analysis(df_merged):
    st.markdown("### ğŸ“ˆ å…ƒãƒ‡ãƒ¼ã‚¿ x æ¤œç´¢çµæœ ã‚¯ãƒ­ã‚¹åˆ†æ")
    st.info("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å…ƒã®åˆ—ã¨ã€æ¤œç´¢ã§å¾—ã‚‰ã‚ŒãŸWhoisæƒ…å ±ã‚’çµ„ã¿åˆã‚ã›ã¦å¯è¦–åŒ–ã—ã¾ã™ã€‚å°åˆ·ç”¨ã«ã‚°ãƒ©ãƒ•å˜ä½“ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚‚å¯èƒ½ã§ã™ã€‚")
    
    # ã‚°ãƒ©ãƒ•è¨­å®šç”¨ã‚«ãƒ©ãƒ 
    # å…ƒãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒ©ãƒ ï¼ˆStatusãªã©å¾Œä»˜ã‘ã®ã‚«ãƒ©ãƒ ã‚’é™¤ãï¼‰
    original_cols = [c for c in df_merged.columns if c not in ['ISP', 'ISP_JP', 'Country', 'Country_JP', 'Proxy Type', 'Status']]
    # Whoisçµæœã®ã‚«ãƒ©ãƒ 
    whois_cols = ['Country_JP', 'ISP_JP', 'Proxy Type', 'Status']
    
    col_x, col_grp, col_chart_type = st.columns(3)
    
    with col_x:
        x_col = st.selectbox("Xè»¸ (ã‚«ãƒ†ã‚´ãƒª/å…ƒã®åˆ—)", original_cols + whois_cols, index=0)
    
    with col_grp:
        group_col = st.selectbox("ç©ã¿ä¸Šã’/è‰²åˆ†ã‘ (Whoisæƒ…å ±ãªã©)", ['(ãªã—)'] + whois_cols + original_cols, index=1)
        
    with col_chart_type:
        chart_type = st.radio("ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—", ["ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ (é›†è¨ˆ)", "ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—"], horizontal=True)

    if not df_merged.empty:
        chart = None
        
        # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†: NaNã‚’æ–‡å­—åˆ—ã«ç½®æ›ã—ã¦Altairã®ã‚¨ãƒ©ãƒ¼å›é¿
        chart_df = df_merged.fillna("N/A").astype(str)

        if chart_type == "ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ (é›†è¨ˆ)":
            if group_col != '(ãªã—)':
                chart = alt.Chart(chart_df).mark_bar().encode(
                    x=alt.X(x_col, title=x_col),
                    y=alt.Y('count()', title='ä»¶æ•°'),
                    color=alt.Color(group_col, title=group_col),
                    tooltip=[x_col, group_col, 'count()']
                ).properties(height=400)
            else:
                chart = alt.Chart(chart_df).mark_bar().encode(
                    x=alt.X(x_col, title=x_col),
                    y=alt.Y('count()', title='ä»¶æ•°'),
                    tooltip=[x_col, 'count()']
                ).properties(height=400)
                
        elif chart_type == "ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—":
             if group_col != '(ãªã—)':
                chart = alt.Chart(chart_df).mark_rect().encode(
                    x=alt.X(x_col, title=x_col),
                    y=alt.Y(group_col, title=group_col),
                    color=alt.Color('count()', title='ä»¶æ•°', scale=alt.Scale(scheme='viridis')),
                    tooltip=[x_col, group_col, 'count()']
                ).properties(height=400)
             else:
                 st.warning("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã«ã¯ã€Œç©ã¿ä¸Šã’/è‰²åˆ†ã‘ã€é …ç›®ã®é¸æŠãŒå¿…è¦ã§ã™ã€‚")

        if chart:
            st.altair_chart(chart, use_container_width=True)
            
            # HTMLãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨
            chart_json = chart.to_dict()
            html_content = generate_cross_analysis_html(chart_json, x_col, group_col if group_col != '(ãªã—)' else 'Count')
            
            st.download_button(
                label="â¬‡ï¸ ã‚¯ãƒ­ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆ(HTML)ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=html_content,
                file_name=f"cross_analysis_{x_col}_vs_{group_col}.html",
                mime="text/html",
                help="ã‚°ãƒ©ãƒ•ã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã§å…¨ç”»é¢è¡¨ç¤ºã—ã€å°åˆ·ã™ã‚‹ã®ã«é©ã—ã¦ã„ã¾ã™ã€‚"
            )


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
def main():
    if 'cancel_search' not in st.session_state: st.session_state['cancel_search'] = False
    if 'raw_results' not in st.session_state: st.session_state['raw_results'] = []
    if 'targets_cache' not in st.session_state: st.session_state['targets_cache'] = []
    if 'is_searching' not in st.session_state: st.session_state['is_searching'] = False
    if 'deferred_ips' not in st.session_state: st.session_state['deferred_ips'] = {} 
    if 'finished_ips' not in st.session_state: st.session_state['finished_ips'] = set() 
    if 'search_start_time' not in st.session_state: st.session_state['search_start_time'] = 0.0 
    if 'target_freq_map' not in st.session_state: st.session_state['target_freq_map'] = {} 
    if 'cidr_cache' not in st.session_state: st.session_state['cidr_cache'] = {} 
    if 'debug_summary' not in st.session_state: st.session_state['debug_summary'] = {}

    tor_nodes = fetch_tor_exit_nodes()
    
    with st.sidebar:
        st.markdown("### ğŸ› ï¸ Menu")
        selected_menu = option_menu(
            menu_title=None,
            options=["Whoisæ¤œç´¢", "ä»•æ§˜ãƒ»è§£èª¬"],
            icons=["search", "book"],
            default_index=0,
            styles={
                "nav-link": {"font-size": "16px", "text-align": "left", "margin": "5px", "--hover-color": "#eee"},
                "nav-link-selected": {"background-color": "#1e3a8a"},
            }
        )
        st.markdown("---")
        # ğŸ†• Proãƒ¢ãƒ¼ãƒ‰è¨­å®š (APIã‚­ãƒ¼å…¥åŠ›)
        st.markdown("#### ğŸ”‘ Pro Mode (Optional)")
        pro_api_key = st.text_input("ipinfo.io API Key", type="password", help="å…¥åŠ›ã™ã‚‹ã¨ipinfo.ioã®é«˜ç²¾åº¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ç©ºæ¬„ã®å ´åˆã¯ip-api.com(ç„¡æ–™)ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚").strip()
        
        st.markdown("---")
        if st.button("ğŸ”„ IPã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢", help="ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå¤ããªã£ãŸå ´åˆã«ã‚¯ãƒªãƒƒã‚¯"):
            st.session_state['cidr_cache'] = {} 
            st.info("IP/CIDRã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")
            st.rerun()

    if selected_menu == "ä»•æ§˜ãƒ»è§£èª¬":
        st.title("ğŸ“– ãƒãƒ‹ãƒ¥ã‚¢ãƒ« & ã‚¬ã‚¤ãƒ‰")
        
        # ğŸ†• ã‚¿ãƒ–ã§æƒ…å ±ã‚’æ•´ç†ã—ã¦è¦‹ã‚„ã™ãã™ã‚‹
        tab1, tab2, tab3 = st.tabs(["ğŸ”° ä½¿ã„æ–¹ãƒ»ãƒ¢ãƒ¼ãƒ‰é¸æŠ", "âš™ï¸ ä»•æ§˜ãƒ»æŠ€è¡“è©³ç´°", "â“ FAQ"])

        with tab1:
            st.markdown("### ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ")
            
            if IS_PUBLIC_MODE:
                st.markdown("""
                1. **å…¥åŠ›**: å·¦å´ã®**ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’è²¼ã‚Šä»˜ã‘ã‚‹**ã‹ã€`.txt` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
                   > âš ï¸ **æ³¨æ„**: å…¬é–‹ã‚µãƒ¼ãƒãƒ¼ç’°å¢ƒã®ãŸã‚ã€Excel/CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯åˆ¶é™ã•ã‚Œã¦ã„ã¾ã™ã€‚
                """)
            else:
                st.markdown("""
                1. **å…¥åŠ›**: å·¦å´ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«è²¼ã‚Šä»˜ã‘ã‚‹ã‹ã€**ãƒ†ã‚­ã‚¹ãƒˆã€CSVã€Excelãƒ•ã‚¡ã‚¤ãƒ«**ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
                   > âœ… **Local Mode**: ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å‹•ä½œã—ã¦ã„ã‚‹ãŸã‚ã€æ©Ÿå¯†æƒ…å ±ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã‚‚å¯èƒ½ã§ã™ã€‚
                """)

            st.markdown("""
            2. **è¨­å®š**: åŸºæœ¬çš„ã«ã¯ãã®ã¾ã¾ã§OKã§ã™ã€‚å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã™ã‚‹å ´åˆã‚„ã€ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ãŒå¿…è¦ãªå ´åˆã¯ã€ä¸‹éƒ¨ã®è¨­å®šã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚
            3. **å®Ÿè¡Œ**: ã€ŒğŸš€ æ¤œç´¢é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¾ã™ã€‚
            """)
            
            st.info("ğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: çµæœãŒå‡ºãŸã‚ã¨ã€ç”»é¢ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€è‡ªå‹•ã§ã‚°ãƒ©ãƒ•åŒ–ã•ã‚ŒãŸåˆ†æãƒ¬ãƒãƒ¼ãƒˆãŒè¦‹ã‚Œã¾ã™ã€‚")

            st.markdown("---")
            st.markdown("### âš™ï¸ è¨­å®šé …ç›®ã®è§£èª¬")
            
            st.markdown("#### 1. è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰ (Display Mode)")
            st.markdown("æ¤œç´¢çµæœã‚’ã©ã®ã‚ˆã†ã«ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹ã‹ã‚’é¸æŠã—ã¾ã™ã€‚")
            
            display_mode_df = pd.DataFrame({
                "ãƒ¢ãƒ¼ãƒ‰å": ["æ¨™æº–ãƒ¢ãƒ¼ãƒ‰", "é›†ç´„ãƒ¢ãƒ¼ãƒ‰", "ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰"],
                "APIé€šä¿¡": ["ã‚ã‚Š (æ¶ˆè²»)", "ã‚ã‚Š (æ¶ˆè²»)", "ãªã— (ç¯€ç´„)"],
                "èª¬æ˜ã¨ãƒ¡ãƒªãƒƒãƒˆ": [
                    "å…¥åŠ›ã•ã‚ŒãŸIPã‚’1è¡Œãšã¤è¡¨ç¤ºã—ã¾ã™ã€‚å€‹åˆ¥ã®åˆ¤å®šçµæœã‚’è©³ã—ãç¢ºèªã—ãŸã„å ´åˆã«æœ€é©ã§ã™ã€‚",
                    "åŒã˜ISPãƒ»å›½ã§ã€é€£ç¶šã™ã‚‹IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’1è¡Œã«ã¾ã¨ã‚ã¾ã™ã€‚ï¼ˆä¾‹: `1.1.1.1 - 1.1.1.5 (x5)`ï¼‰ã€‚å¤§é‡ã®ãƒ­ã‚°ã‹ã‚‰ã€Œã©ã“ã®ä¼šç¤¾ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒå¤šã„ã‹ã€ã‚’æ¦‚è¦³ã™ã‚‹ã®ã«ä¾¿åˆ©ã§ã™ã€‚",
                    "APIé€šä¿¡ã‚’è¡Œã‚ãšã€èª¿æŸ»ç”¨ãƒªãƒ³ã‚¯ã®ç”Ÿæˆã®ã¿è¡Œã„ã¾ã™ã€‚APIåˆ¶é™ã«ã‹ã‹ã£ãŸå ´åˆã‚„ã€å¤–éƒ¨ã¸IPã‚’é€ä¿¡ã—ãŸããªã„å ´åˆã«åˆ©ç”¨ã—ã¾ã™ã€‚"
                ]
            })
            st.table(display_mode_df.set_index("ãƒ¢ãƒ¼ãƒ‰å"))

            st.markdown("#### 2. APIå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ (Processing Speed)")
            st.markdown("æ¤œç´¢ã‚¹ãƒ”ãƒ¼ãƒ‰ã¨å®‰å®šæ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’èª¿æ•´ã—ã¾ã™ã€‚")
            
            api_mode_df = pd.DataFrame({
                "ãƒ¢ãƒ¼ãƒ‰å": ["å®‰å®šæ€§é‡è¦–", "é€Ÿåº¦å„ªå…ˆ"],
                "å‹•ä½œã‚¤ãƒ¡ãƒ¼ã‚¸": ["ğŸ¢ ã‚†ã£ãã‚Šãƒ»ç¢ºå®Ÿ", "ğŸš€ ç´ æ—©ããƒ»ä¸¦åˆ—"],
                "èª¬æ˜": [
                    "å¾…æ©Ÿæ™‚é–“ã‚’é•·ã‚(2.5ç§’)ã«å–ã‚Šã€1ä»¶ãšã¤å‡¦ç†ã—ã¾ã™ã€‚APIã®ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆï¼ˆåˆ¶é™ï¼‰ã«ã‹ã‹ã‚Šã«ããã€ã‚¨ãƒ©ãƒ¼ãŒå‡ºã«ãã„å®‰å…¨é‹è»¢è¨­å®šã§ã™ã€‚",
                    "å¾…æ©Ÿæ™‚é–“ã‚’çŸ­ã(1.4ç§’)ã—ã€2ã¤ã®å‡¦ç†ã‚’åŒæ™‚ã«èµ°ã‚‰ã›ã¾ã™ã€‚å¤§é‡ã®ãƒªã‚¹ãƒˆã‚’æ—©ãå‡¦ç†ã—ãŸã„å ´åˆã«æ¨å¥¨ã•ã‚Œã¾ã™ãŒã€å›ç·šçŠ¶æ³ã«ã‚ˆã£ã¦ã¯åˆ¶é™ã«ã‹ã‹ã‚Šã‚„ã™ããªã‚Šã¾ã™ã€‚"
                ]
            })
            st.table(api_mode_df.set_index("ãƒ¢ãƒ¼ãƒ‰å"))

            st.markdown("#### 3. è©³ç´°ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
            st.markdown("""
            - **ğŸ” é«˜ç²¾åº¦ãƒ¢ãƒ¼ãƒ‰ (RDAP)**
                - `ip-api.com` (ç„¡æ–™ç‰ˆ) ã®æƒ…å ±ã«åŠ ãˆã€å„åœ°åŸŸã®**å…¬å¼ãƒ¬ã‚¸ã‚¹ãƒˆãƒª(RDAP)** ã«ã‚‚å•ã„åˆã‚ã›ã‚’è¡Œã„ã¾ã™ã€‚
                - **ãƒ¡ãƒªãƒƒãƒˆ**: ã€Œé‹ç”¨è€…(ISP)ã€ã ã‘ã§ãªãã€Œæ³•çš„ãªä¿æœ‰çµ„ç¹”(Org)ã€ã¾ã§ç‰¹å®šã§ãã‚‹ç¢ºç‡ãŒä¸ŠãŒã‚Šã¾ã™ã€‚
                - **ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**: é€šä¿¡å›æ•°ãŒå¢—ãˆã‚‹ãŸã‚ã€æ¤œç´¢ã‚¹ãƒ”ãƒ¼ãƒ‰ãŒå¤§å¹…ã«ä½ä¸‹ã—ã¾ã™ã€‚å¾¹åº•çš„ã«è£å–ã‚Šã‚’ã—ãŸã„å ´åˆã®ã¿ONã«ã—ã¦ãã ã•ã„ã€‚
            
            - **ğŸ”‘ Pro Mode (API Key)**
                - ã‚µã‚¤ãƒ‰ãƒãƒ¼ã« `ipinfo.io` ã®APIã‚­ãƒ¼ã‚’å…¥åŠ›ã™ã‚‹ã¨è‡ªå‹•ã§æœ‰åŠ¹ã«ãªã‚Šã¾ã™ã€‚
                - **ãƒ¡ãƒªãƒƒãƒˆ**: VPN/Proxy/Hostingã®åˆ¤å®šç²¾åº¦ãŒåŠ‡çš„ã«å‘ä¸Šã—ã€ä¼æ¥­åã®ç‰¹å®šç²¾åº¦ã‚‚é«˜ã¾ã‚Šã¾ã™ã€‚
            """)

            st.markdown("---")
            st.markdown("### ğŸ’» å‹•ä½œãƒ¢ãƒ¼ãƒ‰ã¨ãƒ­ãƒ¼ã‚«ãƒ«ç‰ˆã®å°å…¥")
            
            st.info("""
            ã“ã®ã‚¢ãƒ—ãƒªã¯ã€å®Ÿè¡Œç’°å¢ƒï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰ã‹ãƒ­ãƒ¼ã‚«ãƒ«ã‹ï¼‰ã«ã‚ˆã£ã¦æ©Ÿèƒ½ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼ãŒå¤‰åŒ–ã—ã¾ã™ã€‚
            æ©Ÿå¯†æ€§ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿ï¼ˆé¡§å®¢ãƒ­ã‚°ç­‰ï¼‰ã‚’æ‰±ã†å ´åˆã‚„ã€å¤§é‡ã®CSV/Excelã‚’å‡¦ç†ã—ãŸã„å ´åˆã¯ã€**Localç‰ˆ** ã®åˆ©ç”¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚
            """)

            # ãƒ¢ãƒ¼ãƒ‰æ¯”è¼ƒè¡¨
            mode_compare_df = pd.DataFrame({
                "æ©Ÿèƒ½ / ç‰¹å¾´": ["Excel/CSV ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "æ©Ÿå¯†æƒ…å ±ã®å–æ‰±", "å®Ÿè¡Œç’°å¢ƒ", "ä¸»ãªç”¨é€”"],
                "â˜ï¸ Public Cloudç‰ˆ": ["âŒ ä¸å¯ (.txtã®ã¿)", "â–³ æ¨å¥¨ã—ãªã„ (å…±æœ‰ã‚µãƒ¼ãƒãƒ¼)", "Streamlit Community Cloud", "æ‰‹è»½ãªå˜ç™ºæ¤œç´¢ãƒ»ãƒ‡ãƒ¢åˆ©ç”¨"],
                "ğŸ  Local Privateç‰ˆ": ["âœ… å¯èƒ½ ", "â— å®‰å…¨ (è‡ªPCå†…ã§å®Œçµ)", "ãƒ­ãƒ¼ã‚«ãƒ«PC / ç¤¾å†…ã‚µãƒ¼ãƒãƒ¼", "å®Ÿå‹™ãƒ»ãƒ­ã‚°è§£æãƒ»å¤§é‡å‡¦ç†"]
            })
            st.table(mode_compare_df.set_index("æ©Ÿèƒ½ / ç‰¹å¾´"))

            st.markdown("#### ğŸ“¥ ãƒ­ãƒ¼ã‚«ãƒ«ç‰ˆ (Local Private Edition) ã®å°å…¥æ–¹æ³•")
            st.markdown("Pythonç’°å¢ƒãŒã‚ã‚Œã°ã€ã©ãªãŸã§ã‚‚åˆ¶é™ãªã—ã®ãƒ­ãƒ¼ã‚«ãƒ«ç‰ˆã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã¯GitHubã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚")
            
            st.markdown("""
            **1. ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®å–å¾—**
            ä»¥ä¸‹ã®ãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆCloneï¼‰ã—ã¦ãã ã•ã„ã€‚
            - ğŸ”— **GitHub Repository**: [github.com/x04z/WhoisApp](https://github.com/x04z/WhoisApp)
            
            **2. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
            ```bash
            pip install streamlit pandas requests streamlit-option-menu altair openpyxl
            ```
            
            **3. ã‚¢ãƒ—ãƒªã®èµ·å‹•**
            ã‚³ãƒãƒ³ãƒ‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¾ãŸã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
            ```bash
            streamlit run WhoisAppxxxx.py
            ```
            ã“ã‚Œã§ãƒ–ãƒ©ã‚¦ã‚¶ãŒç«‹ã¡ä¸ŠãŒã‚Šã€**ã€ŒğŸ  Local Private Editionã€** ã¨ã—ã¦Excelã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ãªã©ãŒè§£æ”¾ã•ã‚ŒãŸçŠ¶æ…‹ã§èµ·å‹•ã—ã¾ã™ã€‚
            """)
 
        with tab2:
            st.markdown("""
            #### 1. ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
            - **IP Geolocation / ISP æƒ…å ±**: 
                - ç„¡æ–™ç‰ˆ: `ip-api.com` (æ¯åˆ†45ãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ¶é™)
                - Proç‰ˆ: `ipinfo.io` (APIã‚­ãƒ¼ã«åŸºã¥ãåˆ¶é™)
            - **Whois (RDAP)**: APNICç­‰ã®å„åœ°åŸŸãƒ¬ã‚¸ã‚¹ãƒˆãƒªå…¬å¼ã‚µãƒ¼ãƒãƒ¼
            - **Torå‡ºå£ãƒãƒ¼ãƒ‰**: Tor Projectå…¬å¼ã‚µã‚¤ãƒˆã‚ˆã‚Šèµ·å‹•æ™‚ã«æœ€æ–°ãƒªã‚¹ãƒˆã‚’å–å¾—

            #### 2. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®ä»•çµ„ã¿ (API vs RDAP)
            - **API (ip-api/ipinfo)**: 
                - **å½¹å‰²**: ã€Œä»Šã€èª°ãŒãã®IPã‚’é‹ç”¨ã—ã¦ã„ã‚‹ã‹ï¼Ÿã€(Service Provider) ã‚’ç­”ãˆã¾ã™ã€‚
                - **ç‰¹å¾´**: é«˜é€Ÿã§ã€Cloudflareã‚„Amazonãªã©ã®ã‚µãƒ¼ãƒ“ã‚¹åãŒè¡¨ç¤ºã•ã‚Œã‚„ã™ã„ã§ã™ã€‚
            - **RDAP (å…¬å¼å°å¸³)**: 
                - **å½¹å‰²**: ã€Œãã®IPã‚¢ãƒ‰ãƒ¬ã‚¹(åœŸåœ°)ã®æ³•çš„ãªæŒã¡ä¸»ã¯èª°ã‹ï¼Ÿã€(Registry Owner) ã‚’ç­”ãˆã¾ã™ã€‚
                - **ç‰¹å¾´**: æ­£ç¢ºã§ã™ãŒã€APNIC-LABSãªã©ã®çµ„ç¹”åãŒè¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
            - **ãƒ¡ãƒªãƒƒãƒˆ**: ã“ã®2ã¤ã‚’è¦‹æ¯”ã¹ã‚‹ã“ã¨ã§ã€ã€Œé‹ç”¨ã®å§”è¨—é–¢ä¿‚ã€ã‚„ã€Œã‚¤ãƒ³ãƒ•ãƒ©ã®è£å´ã€ãŒè¦‹ãˆã¦ãã¾ã™ã€‚

            #### 3. æŠ€è¡“çš„ä»•æ§˜
            - **ä¸¦åˆ—å‡¦ç†**: ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã«ã‚ˆã‚‹é«˜é€Ÿæ¤œç´¢ï¼ˆAPIãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆè‡ªå‹•èª¿æ•´æ©Ÿèƒ½ä»˜ãï¼‰
            - **CIDRã‚­ãƒ£ãƒƒã‚·ãƒ¥**: åŒä¸€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¸¯åŸŸï¼ˆ/24ãªã©ï¼‰ã¸ã®é‡è¤‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å›é¿ã—ã€é«˜é€ŸåŒ–
            """)
            
            st.markdown("#### 4. åˆ¤å®šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®æ„å‘³")
            st.warning("âš ï¸ **Hosting/VPN/Proxy**")
            st.markdown("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã€VPNã‚µãƒ¼ãƒ“ã‚¹ã€ãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒãƒ¼çµŒç”±ã®é€šä¿¡ã§ã™ã€‚ä¸€èˆ¬å®¶åº­ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã§ã¯ãªãã€ãƒœãƒƒãƒˆã‚„åŒ¿ååŒ–ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            st.error("âš ï¸ **Tor Node**")
            st.markdown("ToråŒ¿ååŒ–ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å‡ºå£ãƒãƒ¼ãƒ‰ã§ã™ã€‚æ”»æ’ƒã®å‰å…†ã‚„ã€é«˜ã„åŒ¿åæ€§ã‚’å¿…è¦ã¨ã™ã‚‹é€šä¿¡ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

        with tab3:
            # --- ãƒ¢ãƒ¼ãƒ‰åˆ¥æ¡ˆå†…: FAQ ---
            if IS_PUBLIC_MODE:
                st.markdown("""
                **Q. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚‚å¤§ä¸ˆå¤«ã§ã™ã‹ï¼Ÿ**\n
                A. ç¾åœ¨ã¯ **Public (Cloud) Mode** ã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼ã¯å…±æœ‰ç’°å¢ƒã®ãŸã‚ã€**æ©Ÿå¯†æƒ…å ±ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯æ¨å¥¨ã•ã‚Œã¾ã›ã‚“**ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã¸ã®IPè²¼ã‚Šä»˜ã‘ã‚’åˆ©ç”¨ã™ã‚‹ã‹ã€å€‹äººæƒ…å ±ã‚’å«ã¾ãªã„ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
                """)
            else:
                st.markdown("""
                **Q. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚‚å¤§ä¸ˆå¤«ã§ã™ã‹ï¼Ÿ**\n
                A. ã¯ã„ã€‚ç¾åœ¨ã¯ **Local Mode** ã§å‹•ä½œã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã¯ã‚ãªãŸã®PCï¼ˆã¾ãŸã¯ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚µãƒ¼ãƒãƒ¼ï¼‰å†…ã§å‡¦ç†ã•ã‚Œã€å¤–éƒ¨ã®é–‹ç™ºè€…ç­‰ã«é€ä¿¡ã•ã‚Œã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å®‰å¿ƒã—ã¦æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šæ‰±ãˆã¾ã™ã€‚
                """)

            st.markdown("""
            **Q. æ¤œç´¢ãŒé€”ä¸­ã§æ­¢ã¾ã‚Šã¾ã—ãŸã€‚**\n
            A. APIã®åˆ¶é™ï¼ˆãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆï¼‰ã«ã‹ã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ„ãƒ¼ãƒ«ã¯è‡ªå‹•çš„ã«å¾…æ©Ÿã—ã¦å†é–‹ã—ã¾ã™ãŒã€å¤§é‡ï¼ˆæ•°åƒä»¶ï¼‰ã®æ¤œç´¢ã‚’è¡Œã†å ´åˆã¯æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚ã€Œå¾…æ©Ÿä¸­ã€ã®è¡¨ç¤ºãŒå‡ºã¦ã„ã‚‹å ´åˆã¯ãã®ã¾ã¾ãŠå¾…ã¡ãã ã•ã„ã€‚

            **Q. ipinfoã®APIã‚­ãƒ¼ã¯ã©ã“ã§æ‰‹ã«å…¥ã‚Šã¾ã™ã‹ï¼Ÿ**\n
            A. [ipinfo.io](https://ipinfo.io/signup) ã‹ã‚‰ç„¡æ–™ã§ç™»éŒ²ãƒ»å–å¾—ã§ãã¾ã™ï¼ˆç„¡æ–™æ ã‚ã‚Šï¼‰ã€‚

            **Q. ISPåã¨ [RDAP: ã€‡ã€‡] ã®åå‰ãŒé•ã†ã®ã§ã™ãŒï¼Ÿ**\n
            A. **ãã‚Œã¯ã€Œé‹ç”¨è€…ã€ã¨ã€ŒæŒã¡ä¸»ã€ã®é•ã„ã§ã™ã€‚** ä¾‹ãˆã° `1.1.1.1` ã¨ã„ã†IPã‚¢ãƒ‰ãƒ¬ã‚¹ã®å ´åˆï¼š
            * **ISP (API)**: `Cloudflare, Inc.` (DNSã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¦ã„ã‚‹é‹ç”¨è€…)
            * **RDAP (å°å¸³)**: `APNIC-LABS` (IPã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä¿æœ‰ã—ã¦ã„ã‚‹ç ”ç©¶çµ„ç¹”)
            ã“ã®ã‚ˆã†ã«è¡¨ç¤ºã•ã‚Œã‚‹ã®ã¯ãƒã‚°ã§ã¯ãªãã€ã“ã®ãƒ„ãƒ¼ãƒ«ã®ã€Œé«˜ç²¾åº¦ãƒ¢ãƒ¼ãƒ‰ã€ãŒã€**IPã‚¢ãƒ‰ãƒ¬ã‚¹ã®ã€Œè¡¨ã®é‹ç”¨è€…ã€ã¨ã€Œè£ã®æ‰€æœ‰è€…ã€ã®ä¸¡æ–¹ã‚’æ­£ã—ãè¡¨ã—ã¦ã„ã‚‹è¨¼æ‹ **ã§ã™ã€‚
            
            **Q. ISPåã¨RDAPã®åå‰ãŒç•°ãªã‚‹å ´åˆã€ç™ºä¿¡è€…æƒ…å ±é–‹ç¤ºã‚’ã©ã¡ã‚‰ã«è«‹æ±‚ã™ã‚Œã°ã„ã„ã§ã—ã‚‡ã†ã‹ï¼Ÿ**\n
            A. å€‹äººï¼ˆå¥‘ç´„è€…ï¼‰ã®æƒ…å ±ã‚’æŒã£ã¦ã„ã‚‹ã®ã¯**è¡¨ã®é‹ç”¨è€…ã§ã‚ã‚‹ã€ŒISP / ãƒ—ãƒ­ãƒã‚¤ãƒ€ã€**ã®æ–¹ã§ã™ã€‚RDAPã®æƒ…å ±ã¯ã‚ãã¾ã§ã€Œãã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ãƒ–ãƒ­ãƒƒã‚¯ã‚’ç®¡ç†ã—ã¦ã„ã‚‹çµ„ç¹”ã€ã®æƒ…å ±ã§ã‚ã‚Šã€å®Ÿéš›ã®åˆ©ç”¨è€…æƒ…å ±ã¯æŒã£ã¦ã„ãªã„ã“ã¨ãŒå¤šã„ã§ã™ã€‚ç™ºä¿¡è€…æƒ…å ±é–‹ç¤ºè«‹æ±‚ã‚’è¡Œã†å ´åˆã¯ã€**ISPåã‚’ä½¿ã£ã¦æ‰‹ç¶šãã‚’è¡Œã£ã¦ãã ã•ã„**ã€‚
            """)
        return

    # --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼šWhoisæ¤œç´¢ã‚¿ãƒ– ---   
    # ğŸ†• ãƒ¢ãƒ¼ãƒ‰è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯
    if IS_PUBLIC_MODE:
        mode_title = "â˜ï¸ Public Cloud Edition (æ©Ÿèƒ½åˆ¶é™ã‚ã‚Š)"
        mode_color = "gray"
    else:
        mode_title = "ğŸ  Local Private Edition (ãƒ•ãƒ«æ©Ÿèƒ½ç‰ˆ)"
        mode_color = "green"

    st.title("ğŸŒ æ¤œç´¢å¤§è‡£ - Whois & IP Intelligence -")
    st.markdown(f"**Current Mode:** <span style='color:{mode_color}; font-weight:bold;'>{mode_title}</span>", unsafe_allow_html=True)
    col_input1, col_input2 = st.columns([1, 1])

    with col_input1:
        manual_input = st.text_area(
            "ğŸ“‹ ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ› (IP/ãƒ‰ãƒ¡ã‚¤ãƒ³)",
            height=150,
            placeholder="8.8.8.8\nexample.com\n2404:6800:..."
        )

    with col_input2:
        # --- ãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã‚‹ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ¶é™ã®åˆ‡ã‚Šæ›¿ãˆ ---
        if IS_PUBLIC_MODE:
            # å…¬é–‹ãƒ¢ãƒ¼ãƒ‰ (stç‰ˆã®æŒ™å‹•): txtã®ã¿è¨±å¯ã€è­¦å‘Šã‚ã‚Š
            allowed_types = ['txt']
            label_text = "ğŸ“‚ IPãƒªã‚¹ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (.txtã®ã¿)"
            help_text = "â€» 1è¡Œã«1ã¤ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’è¨˜è¼‰"
        else:
            # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰ (myç‰ˆã®æŒ™å‹•): csv/excelè¨±å¯
            allowed_types = ['txt', 'csv', 'xlsx', 'xls']
            label_text = "ğŸ“‚ ãƒªã‚¹ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (txt/csv/xlsx)"
            help_text = "â€» 1è¡Œã«1ã¤ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’è¨˜è¼‰ã€ã¾ãŸã¯CSV/Excelã®IPåˆ—ã‚’è‡ªå‹•æ¤œå‡ºã—ã¾ã™"

        uploaded_file = st.file_uploader(label_text, type=allowed_types)
        st.caption(help_text)
        
        raw_targets = []
        df_orig = None # åˆæœŸåŒ–

        if manual_input:
            raw_targets.extend(manual_input.splitlines())
        
        if uploaded_file:
            # --- å…¬é–‹ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®èª­ã¿è¾¼ã¿å‡¦ç† (stç‰ˆãƒ­ã‚¸ãƒƒã‚¯) ---
            if IS_PUBLIC_MODE:
                 try:
                    # ã‚·ãƒ³ãƒ—ãƒ«ã«ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦èª­ã¿è¾¼ã‚€
                    string_data = uploaded_file.read().decode("utf-8")
                    raw_targets.extend(string_data.splitlines())
                    
                    # å…ƒãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ æ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–
                    st.session_state['original_df'] = None
                    st.session_state['ip_column_name'] = None
                    
                    st.info(f"ğŸ“„ ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿è¾¼ã¿å®Œäº†: {len(raw_targets)} è¡Œ")

                 except Exception as e:
                    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            
            # --- ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã®èª­ã¿è¾¼ã¿å‡¦ç† (myç‰ˆãƒ­ã‚¸ãƒƒã‚¯) ---
            else:
                ip_col = None
                try:
                    if uploaded_file.name.endswith('.csv'):
                        df_orig = pd.read_csv(uploaded_file)
                    elif uploaded_file.name.endswith(('.xlsx', '.xls')):
                        df_orig = pd.read_excel(uploaded_file)
                    else:
                        # TXTãƒ•ã‚¡ã‚¤ãƒ«
                        raw_targets.extend(uploaded_file.read().decode("utf-8").splitlines())
                        st.session_state['original_df'] = None
                        st.session_state['ip_column_name'] = None

                    if df_orig is not None:
                        st.session_state['original_df'] = df_orig
                        for col in df_orig.columns:
                            sample = df_orig[col].dropna().head(10).astype(str)
                            if any(is_valid_ip(val.strip()) for val in sample):
                                ip_col = col
                                break
                        
                        if ip_col:
                            st.session_state['ip_column_name'] = ip_col
                            raw_targets.extend(df_orig[ip_col].dropna().astype(str).tolist())
                            
                            # --- æ–°æ©Ÿèƒ½ï¼šã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ---
                            st.info(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {len(df_orig)} è¡Œ / IPåˆ—: `{ip_col}`")
                            with st.expander("ğŸ‘€ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
                                st.dataframe(df_orig)
                            # ---------------------------------------------
                        else:
                            st.error("ãƒ•ã‚¡ã‚¤ãƒ«å†…ã«IPã‚¢ãƒ‰ãƒ¬ã‚¹ã®åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

                except Exception as e:
                    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    # --- å…¬é–‹ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è­¦å‘Šã‚’è¡¨ç¤º ---
    if IS_PUBLIC_MODE:
        st.warning("""
        **ğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¸Šã®æ³¨æ„**
        * **ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¨å¥¨**: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚ˆã‚Šã‚‚ã€å·¦å´ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã¸ã®**ã‚³ãƒ”ãƒ¼ï¼†ãƒšãƒ¼ã‚¹ãƒˆ**ã®æ–¹ãŒã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆä½œæˆè€…æƒ…å ±ãªã©ï¼‰ãŒå«ã¾ã‚Œãªã„ãŸã‚å®‰å…¨ã§ã™ã€‚
        * **ãƒ•ã‚¡ã‚¤ãƒ«åã«æ³¨æ„**: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å ´åˆã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«åã«æ©Ÿå¯†æƒ…å ±ï¼ˆä¾‹: `ClientA_Log.txt`ï¼‰ã‚’å«ã‚ãšã€`list.txt` ãªã©ã®ç„¡æ©Ÿè³ªãªåå‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
        """)
    
    cleaned_raw_targets_list = []
    target_freq_counts = {}

    if raw_targets:
        cleaned_raw_targets_list = [clean_ocr_error_chars(t) for t in raw_targets]
        target_freq_counts = pd.Series(cleaned_raw_targets_list).value_counts().to_dict()
    else:
        target_freq_counts = {}

    targets = []
    ocr_error_chars = set('Iil|OoSsAaBâ…¡')

    for t in raw_targets:
        original_t = t
        is_ocr_error_likely = any(c in ocr_error_chars for c in original_t)
        if is_ocr_error_likely:
            cleaned_t = clean_ocr_error_chars(original_t)
            if is_valid_ip(cleaned_t):
                if cleaned_t not in targets: targets.append(cleaned_t)
                continue
            t = original_t
        
        invalid_ip_chars = set('ghijklmnopqrstuvwxyz')
        has_hyphen = '-' in t
        has_strictly_domain_char = any(c in invalid_ip_chars for c in t.lower())
        is_likely_domain_or_host = has_hyphen or has_strictly_domain_char
    
        if is_valid_ip(t):
            if t not in targets: targets.append(t)
        elif is_likely_domain_or_host:
            if t not in targets: targets.append(t)
        else:
            cleaned_t_final = clean_ocr_error_chars(t)
            if cleaned_t_final not in targets: targets.append(cleaned_t_final)

    has_new_targets = (targets != st.session_state.targets_cache)
    
    if has_new_targets or 'target_freq_map' not in st.session_state:
        st.session_state['target_freq_map'] = target_freq_counts
        st.session_state['original_input_list'] = cleaned_raw_targets_list
    ip_targets = [t for t in targets if is_valid_ip(t)]
    domain_targets = [t for t in targets if not is_valid_ip(t)]
    ipv6_count = sum(1 for t in ip_targets if not is_ipv4(t))
    ipv4_count = len(ip_targets) - ipv6_count

    st.markdown("---")
    st.markdown("### âš™ï¸ æ¤œç´¢è¡¨ç¤ºè¨­å®š")
    
    col_set1, col_set2 = st.columns(2)
    with col_set1:
        display_mode = st.radio(
            "**è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰:** (æ¤œç´¢çµæœã®è¡¨ç¤ºå½¢å¼ã¨APIä½¿ç”¨æœ‰ç„¡ã‚’è¨­å®š)",
            ("æ¨™æº–ãƒ¢ãƒ¼ãƒ‰", "é›†ç´„ãƒ¢ãƒ¼ãƒ‰ (IPv4 Group)", "ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ (APIãªã—)"),
            key="display_mode_radio",
            horizontal=False
        )
    
    with col_set2:
        api_mode_selection = st.radio(
            "**API å‡¦ç†ãƒ¢ãƒ¼ãƒ‰:** (é€Ÿåº¦ã¨å®‰å®šæ€§ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•)",
            list(MODE_SETTINGS.keys()),
            key="api_mode_radio",
            horizontal=False
        )
        # RDAPã‚ªãƒ—ã‚·ãƒ§ãƒ³
        use_rdap_option = st.checkbox("ğŸ” é«˜ç²¾åº¦ãƒ¢ãƒ¼ãƒ‰ (RDAPå…¬å¼å°å¸³ã®ä½µç”¨ - ä½é€Ÿ)", value=False, help="ç„¡æ–™APIã®ISPæƒ…å ±ã«åŠ ãˆã€RDAP(å…¬å¼å°å¸³)ã‹ã‚‰æœ€æ–°ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åã‚’å–å¾—ã—ã¾ã™ã€‚é€šä¿¡ãŒå¢—ãˆã‚‹ãŸã‚å‡¦ç†ãŒé…ããªã‚Šã¾ã™ã€‚")
    
    selected_settings = MODE_SETTINGS[api_mode_selection]
    max_workers = selected_settings["MAX_WORKERS"]
    delay_between_requests = selected_settings["DELAY_BETWEEN_REQUESTS"]
    rate_limit_wait_seconds = RATE_LIMIT_WAIT_SECONDS

    mode_mapping = {
        "æ¨™æº–ãƒ¢ãƒ¼ãƒ‰": "æ¨™æº–ãƒ¢ãƒ¼ãƒ‰ (1ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ = 1è¡Œ)",
        "é›†ç´„ãƒ¢ãƒ¼ãƒ‰ (IPv4 Group)": "é›†ç´„ãƒ¢ãƒ¼ãƒ‰ (IPv4ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ISP/å›½åˆ¥ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–)",
        "ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ (APIãªã—)": "ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ (APIãªã— - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªãƒ³ã‚¯ã®ã¿)"
    }
    current_mode_full_text = mode_mapping[display_mode]

    st.markdown("---")
    col_act1, col_act2 = st.columns([3, 1])

    is_currently_searching = st.session_state.is_searching and not st.session_state.cancel_search
    
    total_ip_targets_for_display = len(ip_targets) + len(st.session_state.deferred_ips)

    with col_act1:
        st.success(f"**Target:** IPv4: {ipv4_count} / IPv6: {ipv6_count} / Domain: {len(domain_targets)} (Pending: {len(st.session_state.deferred_ips)}) / **CIDR Cache:** {len(st.session_state.cidr_cache)}")
        if pro_api_key:
            st.info("ğŸ”‘ **Pro Mode Active:** ipinfo.io ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¾ã™")

    with col_act2:
        if is_currently_searching:
            if st.button("âŒ ä¸­æ­¢", type="secondary", use_container_width=True):
                st.session_state.cancel_search = True
                st.session_state.is_searching = False
                st.session_state.deferred_ips = {}
                st.rerun()
        else:
            execute_search = st.button(
            "ğŸš€ æ¤œç´¢é–‹å§‹",
            type="primary",
            use_container_width=True,
            disabled=(len(targets) == 0 and len(st.session_state.deferred_ips) == 0)
            )

    if ('execute_search' in locals() and execute_search and (has_new_targets or len(st.session_state.deferred_ips) > 0)) or is_currently_searching:
        
        if ('execute_search' in locals() and execute_search and has_new_targets and len(targets) > 0):
            st.session_state.is_searching = True
            st.session_state.cancel_search = False
            st.session_state.raw_results = []
            st.session_state.deferred_ips = {}
            st.session_state.finished_ips = set()
            st.session_state.targets_cache = targets
            st.session_state.search_start_time = time.time()
            st.rerun() 
            
        elif is_currently_searching:
            targets = st.session_state.targets_cache
            ip_targets = [t for t in targets if is_valid_ip(t)]
            domain_targets = [t for t in targets if not is_valid_ip(t)]

            st.subheader("â³ å‡¦ç†ä¸­...")
            
            total_targets = len(targets)
            total_ip_api_targets = len(ip_targets)
            
            ip_targets_to_process = [ip for ip in ip_targets if ip not in st.session_state.finished_ips]
            
            current_time = time.time()
            ready_to_retry_ips = []
            deferred_ips_new = {}
            for ip, defer_time in st.session_state.deferred_ips.items():
                if current_time >= defer_time:
                    ready_to_retry_ips.append(ip)
                else:
                    deferred_ips_new[ip] = defer_time
            
            st.session_state.deferred_ips = deferred_ips_new
            
            immediate_ip_queue_unique = []
            for ip in ip_targets_to_process:
                if ip not in st.session_state.deferred_ips and ip not in immediate_ip_queue_unique:
                    immediate_ip_queue_unique.append(ip)

            immediate_ip_queue = immediate_ip_queue_unique
            immediate_ip_queue.extend(ready_to_retry_ips)
            
            if "ç°¡æ˜“" in current_mode_full_text:
                if not st.session_state.raw_results:
                    results_list = []
                    for t in targets:
                        results_list.append(get_simple_mode_details(t))
                    st.session_state.raw_results = results_list
                    st.session_state.finished_ips.update(targets)
                    st.session_state.is_searching = False
                    st.rerun()

            else:
                if not any(res['ISP'] == 'Domain/Host' for res in st.session_state.raw_results) and domain_targets:
                    st.session_state.raw_results.extend([get_domain_details(d) for d in domain_targets])
                    st.session_state.finished_ips.update(domain_targets)
                    
                prog_bar_container = st.empty()
                status_text_container = st.empty()
                summary_container = st.empty() 

                if immediate_ip_queue:
                    cidr_cache_snapshot = st.session_state.cidr_cache.copy() 
                    
                    with ThreadPoolExecutor(max_workers=max_workers) as executor:
                        future_to_ip = {
                            executor.submit(
                                get_ip_details_from_api, 
                                ip, 
                                cidr_cache_snapshot, 
                                delay_between_requests, 
                                rate_limit_wait_seconds,
                                tor_nodes,
                                use_rdap_option, # RDAPã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æ¸¡ã™
                                pro_api_key # APIã‚­ãƒ¼ã‚’æ¸¡ã™
                            ): ip for ip in immediate_ip_queue
                        }
                        remaining = set(future_to_ip.keys())
                        
                        while remaining and not st.session_state.cancel_search:
                            done, remaining = wait(remaining, timeout=0.1, return_when=FIRST_COMPLETED)
                            
                            for f in done:
                                res_tuple = f.result()
                                res = res_tuple[0]
                                new_cache_entry = res_tuple[1]
                                ip = res['Target_IP']
                                
                                if new_cache_entry:
                                    st.session_state.cidr_cache.update(new_cache_entry)
                                
                                if res.get('Status', '').startswith('Success'):
                                    st.session_state.raw_results.append(res)
                                    st.session_state.finished_ips.add(ip)
                                elif res.get('Defer_Until'):
                                    st.session_state.deferred_ips[ip] = res['Defer_Until']
                                else:
                                    st.session_state.raw_results.append(res)
                                    st.session_state.finished_ips.add(ip)

                            if total_ip_api_targets > 0:
                                processed_api_ips_count = len([ip for ip in st.session_state.finished_ips if is_valid_ip(ip)])
                                pct = int(processed_api_ips_count / total_ip_api_targets * 100)
                                elapsed_time = time.time() - st.session_state.search_start_time
                                eta_seconds = 0
                                if processed_api_ips_count > 0:
                                    rate = processed_api_ips_count / elapsed_time
                                    remaining_count = total_ip_api_targets - processed_api_ips_count
                                    eta_seconds = math.ceil(remaining_count / rate)
                                
                                eta_display = "è¨ˆç®—ä¸­..."
                                if eta_seconds > 0:
                                    minutes = int(eta_seconds // 60)
                                    seconds = int(eta_seconds % 60)
                                    eta_display = f"{minutes:02d}:{seconds:02d}"
                                    
                                with prog_bar_container:
                                    st.progress(pct)
                                with status_text_container:
                                    st.caption(f"**Progress:** {processed_api_ips_count}/{total_ip_api_targets} | **Deferred:** {len(st.session_state.deferred_ips)} | **CIDR Cache:** {len(st.session_state.cidr_cache)} | **Remaining Time:** {eta_display}")
                                
                                isp_df, country_df, freq_df, country_all_df, isp_full_df, country_full_df, freq_full_df = summarize_in_realtime(st.session_state.raw_results)
                                with summary_container.container():
                                    st.markdown("---")
                                    draw_summary_content(isp_df, country_df, freq_df, country_all_df, "ğŸ“Š Real-time analysis")
                                st.markdown("---")

                            if not remaining and not st.session_state.deferred_ips:
                                break
                            
                            if st.session_state.deferred_ips:
                                st.rerun()  
                            
                            time.sleep(0.5) 
                            
                        if total_ip_api_targets > 0 and not st.session_state.deferred_ips:
                            processed_api_ips_count = len([ip for ip in st.session_state.finished_ips if is_valid_ip(ip)])
                            final_pct = int(processed_api_ips_count / total_ip_api_targets * 100)
                            with prog_bar_container:
                                st.progress(final_pct)
                            with status_text_container:
                                st.caption(f"**Progress:** {processed_api_ips_count}/{total_ip_api_targets} | **Deferred:** {len(st.session_state.deferred_ips)} | **CIDR Cache:** {len(st.session_state.cidr_cache)} | **Remaining Time:** å®Œäº†")
                        
                if len(st.session_state.finished_ips) == total_targets and not st.session_state.deferred_ips:
                    st.session_state.is_searching = False
                    st.info("âœ… å…¨ã¦ã®æ¤œç´¢ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                    summary_container.empty()
                    st.rerun()
                
                elif st.session_state.deferred_ips and not st.session_state.cancel_search:
                    next_retry_time = min(st.session_state.deferred_ips.values())
                    wait_time = max(1, int(next_retry_time - time.time()))
                    
                    prog_bar_container.empty()
                    status_text_container.empty()
                    summary_container.empty()
                    st.warning(f"âš ï¸ **APIãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆã«é”ã—ã¾ã—ãŸã€‚** éš”é›¢ä¸­ã® **{len(st.session_state.deferred_ips)}** ä»¶ã®IPã‚¢ãƒ‰ãƒ¬ã‚¹ã¯ **{wait_time}** ç§’å¾Œã«å†è©¦è¡Œã•ã‚Œã¾ã™ã€‚")
                    time.sleep(min(5, wait_time)) 
                    st.rerun()

                elif st.session_state.cancel_search:
                    prog_bar_container.empty()
                    status_text_container.empty()
                    summary_container.empty()
                    st.warning("æ¤œç´¢ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ­¢ã•ã‚Œã¾ã—ãŸã€‚")
                    st.session_state.is_searching = False
                    st.rerun()


    # --- çµæœè¡¨ç¤º ---
    if st.session_state.raw_results or st.session_state.deferred_ips:
        res = st.session_state.raw_results
        
        if st.session_state.get('debug_summary'):
            with st.expander("ğŸ› ï¸ ãƒ‡ãƒãƒƒã‚°æƒ…å ± (é›†è¨ˆãƒ‡ãƒ¼ã‚¿ç¢ºèªç”¨)", expanded=False):
                st.markdown("**API å‡¦ç†ãƒ¢ãƒ¼ãƒ‰è¨­å®š**")
                st.write(f"MAX_WORKERS: {max_workers}")
                st.write(f"DELAY_BETWEEN_REQUESTS: {delay_between_requests}")
                st.markdown("---")
                st.json(st.session_state['debug_summary'].get('country_code_counts', {}))
                st.json(st.session_state['debug_summary'].get('country_all_df', []))
                st.markdown("---")
                st.json(st.session_state.get('cidr_cache', {}))

        
        successful_results = [r for r in res if r['Status'].startswith('Success') or r['Status'].startswith('Aggregated')]
        error_results = [r for r in res if not (r['Status'].startswith('Success') or r['Status'].startswith('Aggregated'))]
        
        for ip, defer_time in st.session_state.deferred_ips.items():
            status = f"Pending (Retry in {max(0, int(defer_time - time.time()))}s)"
            error_results.append({
                'Target_IP': ip, 'ISP': 'N/A', 'Country': 'N/A', 'CountryCode': 'N/A', 'RIR_Link': get_authoritative_rir_link(ip, 'N/A'),
                'Secondary_Security_Links': create_secondary_links(ip), 
                'Status': status
            })
        
        if "é›†ç´„" in current_mode_full_text:
            display_res = group_results_by_isp(successful_results)
            display_res.extend(error_results)
        else:
            display_res = successful_results + error_results
            target_order = {ip: i for i, ip in enumerate(targets)}
            display_res.sort(key=lambda x: target_order.get(get_copy_target(x['Target_IP']), float('inf')))

        display_results(display_res, current_mode_full_text, display_mode)
        
        if not st.session_state.is_searching or st.session_state.cancel_search:
            isp_df, country_df, freq_df, country_all_df, isp_full_df, country_full_df, freq_full_df = summarize_in_realtime(st.session_state.raw_results)
            
            st.markdown("---")
            draw_summary_content(isp_df, country_df, freq_df, country_all_df, "âœ… é›†è¨ˆçµæœ")

            # --- å…ƒãƒ‡ãƒ¼ã‚¿çµåˆå‡¦ç†ï¼ˆç”»é¢è¡¨ç¤º & ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…±é€šï¼‰ ---
            df_with_res = pd.DataFrame() # åˆæœŸåŒ–
            
            # 1. CSV/Excelã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã¨çµåˆï¼‰
            if st.session_state.get('original_df') is not None and st.session_state.get('ip_column_name'):
                df_with_res = st.session_state['original_df'].copy()
                ip_col = st.session_state['ip_column_name']
                results = st.session_state.get('raw_results', []) 
                
                if results:
                    res_dict = {r['Target_IP']: r for r in results}

                    # å„è¡Œã®IPã«åŸºã¥ã„ã¦çµæœã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
                    isps, isps_jp, countries, countries_jp, proxy_type, statuses, rdaps = [], [], [], [], [], [], []
                    for ip_val in df_with_res[ip_col]:
                        ip_val_str = str(ip_val).strip()
                        info = res_dict.get(ip_val_str, {})
                        isps.append(info.get('ISP', 'N/A'))
                        isps_jp.append(info.get('ISP_JP', 'N/A')) 
                        countries.append(info.get('Country', 'N/A'))
                        countries_jp.append(info.get('Country_JP', 'N/A'))
                        proxy_type.append(info.get('Proxy_Type', ''))
                        statuses.append(info.get('Status', 'N/A'))
                        rdaps.append(info.get('RDAP', ''))
                    
                    # çµåˆ (åˆ—ã®æŒ¿å…¥)
                    insert_idx = df_with_res.columns.get_loc(ip_col) + 1
                    df_with_res.insert(insert_idx, 'Status', statuses)
                    df_with_res.insert(insert_idx, 'Proxy Type', proxy_type)
                    df_with_res.insert(insert_idx, 'RDAP', rdaps) # RDAPåˆ—
                    df_with_res.insert(insert_idx, 'Country_JP', countries_jp)
                    df_with_res.insert(insert_idx, 'Country', countries)
                    df_with_res.insert(insert_idx, 'ISP_JP', isps_jp)
                    df_with_res.insert(insert_idx, 'ISP', isps)

            # 2. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒãªã„å ´åˆï¼ˆæ¤œç´¢çµæœã®ã¿ã‹ã‚‰åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼‰ğŸ†•
            elif st.session_state.raw_results:
                # æ¤œç´¢çµæœãƒªã‚¹ãƒˆã‚’ãƒ™ãƒ¼ã‚¹ã«DataFrameåŒ–
                temp_data = []
                for res in st.session_state.raw_results:
                    # å¿…è¦ãªã‚«ãƒ©ãƒ ã®ã¿æŠ½å‡ºãƒ»ãƒªãƒãƒ¼ãƒ 
                    row = {
                        'Target_IP': res.get('Target_IP'),
                        'ISP': res.get('ISP'),
                        'ISP_JP': res.get('ISP_JP'),
                        'Country': res.get('Country'),
                        'Country_JP': res.get('Country_JP'),
                        'RDAP': res.get('RDAP', ''),
                        'Proxy Type': res.get('Proxy_Type', ''), # ã‚­ãƒ¼åã‚’çµ±ä¸€
                        'Status': res.get('Status')
                    }
                    temp_data.append(row)
                df_with_res = pd.DataFrame(temp_data)

            # --- æ–°æ©Ÿèƒ½ï¼šå…ƒãƒ‡ãƒ¼ã‚¿ x æ¤œç´¢çµæœ ã‚¯ãƒ­ã‚¹åˆ†æè¡¨ç¤º ---
            if not df_with_res.empty:
                st.markdown("---")
                render_merged_analysis(df_with_res)
            # ------------------------------------------------

            # --- å…¨ä»¶é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
            st.markdown("### ğŸ“Š é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ç‰ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
            # (ä¸­ç•¥: csvãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³éƒ¨åˆ†ã¯ãã®ã¾ã¾)
            col_full_dl1, col_full_dl2, col_full_dl3, col_full_dl4 = st.columns(4)
            
            with col_full_dl1:
                st.download_button(
                    "â¬‡ï¸ å¯¾è±¡IP ã‚«ã‚¦ãƒ³ãƒˆ (å…¨ä»¶)",
                    freq_full_df.to_csv(index=False).encode('utf-8-sig'),
                    "target_ip_frequency_all.csv",
                    "text/csv",
                    use_container_width=True
                )
            with col_full_dl2:
                st.download_button(
                    "â¬‡ï¸ ISPåˆ¥ ã‚«ã‚¦ãƒ³ãƒˆ (å…¨ä»¶)",
                    isp_full_df.to_csv(index=False).encode('utf-8-sig'),
                    "isp_counts_all.csv",
                    "text/csv",
                    use_container_width=True
                )
            with col_full_dl3:
                st.download_button(
                    "â¬‡ï¸ å›½åˆ¥ ã‚«ã‚¦ãƒ³ãƒˆ (å…¨ä»¶)",
                    country_full_df.to_csv(index=False).encode('utf-8-sig'),
                    "country_counts_all.csv",
                    "text/csv",
                    use_container_width=True
                )
            
            with col_full_dl4:
                # å…¨ä»¶ã‚°ãƒ©ãƒ•HTMLãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
                html_report = generate_full_report_html(isp_full_df, country_full_df, freq_full_df)
                st.download_button(
                    "â¬‡ï¸ å…¨ä»¶ã‚°ãƒ©ãƒ•HTMLãƒ¬ãƒãƒ¼ãƒˆ",
                    html_report,
                    "whois_analysis_report.html",
                    "text/html",
                    use_container_width=True
                )

        
        st.markdown("### â¬‡ï¸ æ¤œç´¢çµæœãƒªã‚¹ãƒˆã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        col_dl1, col_dl2, col_dl3 = st.columns(3)
        # 1. ç”»é¢è¡¨ç¤ºé †ãƒ‡ãƒ¼ã‚¿
        csv_display = pd.DataFrame(display_res).drop(columns=['CountryCode', 'Secondary_Security_Links', 'RIR_Link'], errors='ignore').astype(str)
        with col_dl1:
            st.download_button("â¬‡ï¸ CSV (ç”»é¢è¡¨ç¤ºé †)", csv_display.to_csv(index=False).encode('utf-8-sig'), "whois_results_display.csv", "text/csv", use_container_width=True)
            # Excel (Display)
            excel_display = convert_df_to_excel(csv_display)
            st.download_button("â¬‡ï¸ Excel (ç”»é¢è¡¨ç¤ºé †)", excel_display, "whois_results_display.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)

        # 2. å…¨å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆå…¥åŠ›é †ï¼‰
        result_lookup = {r['Target_IP']: r for r in st.session_state.raw_results}
        full_output_data = []
        for original_t in st.session_state.get('original_input_list', []):
            if original_t in result_lookup:
                full_output_data.append(result_lookup[original_t])
            else:
                full_output_data.append({'Target_IP': original_t, 'ISP': 'N/A', 'ISP_JP': 'N/A', 'Country': 'N/A', 'Country_JP': 'N/A', 'Status': 'Pending/Error'})
        
        csv_full = pd.DataFrame(full_output_data).drop(columns=['CountryCode', 'Secondary_Security_Links', 'RIR_Link'], errors='ignore').astype(str)
        with col_dl2:
            st.download_button("â¬‡ï¸ CSV (å…¨å…¥åŠ›ãƒ‡ãƒ¼ã‚¿é †)", csv_full.to_csv(index=False).encode('utf-8-sig'), "whois_results_full.csv", "text/csv", use_container_width=True)
            # Excel (Full)
            excel_full = convert_df_to_excel(csv_full)
            st.download_button("â¬‡ï¸ Excel (å…¨å…¥åŠ›ãƒ‡ãƒ¼ã‚¿é †)", excel_full, "whois_results_full.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)

        with col_dl3:
            # 3. åˆ†æä»˜ãExcel (å…¨ãƒ¢ãƒ¼ãƒ‰ã§æœ‰åŠ¹åŒ–) ğŸ†•
            if not df_with_res.empty:
                st.markdown("**ğŸ” åˆ†æä»˜ãExcel (Pivot/Graph)**")
                
                # æ™‚é–“å¸¯åˆ†æç”¨ã®åˆ—é¸æŠãƒœãƒƒã‚¯ã‚¹ (å­˜åœ¨ã™ã‚‹å ´åˆã®ã¿)
                time_cols = [c for c in df_with_res.columns if 'date' in c.lower() or 'time' in c.lower() or 'jst' in c.lower()]
                default_idx = df_with_res.columns.get_loc(time_cols[0]) if time_cols else 0
                
                selected_time_col = None
                if time_cols:
                    selected_time_col = st.selectbox(
                        "æ™‚é–“å¸¯åˆ†æ(Houråˆ—)ã«ä½¿ã†æ—¥æ™‚åˆ—ã‚’é¸æŠ:", 
                        df_with_res.columns, 
                        index=default_idx,
                        key="time_col_selector"
                    )
                else:
                    st.caption("â€» æ—¥æ™‚åˆ—ãŒãªã„ãŸã‚æ™‚é–“å¸¯åˆ†æã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™")

                # Advanced Excelç”Ÿæˆ (v5.0)
                excel_advanced = create_advanced_excel(df_with_res, selected_time_col)
                
                st.download_button(
                    "â¬‡ï¸ Excel (åˆ†æãƒ»ã‚°ãƒ©ãƒ•ä»˜ã)", 
                    excel_advanced, 
                    "whois_analysis_master.xlsx", 
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", 
                    use_container_width=True,
                    help="ç”Ÿãƒ‡ãƒ¼ã‚¿ã«åŠ ãˆã€ISPåˆ¥ãƒ»æ™‚é–“å¸¯åˆ¥ã®é›†è¨ˆè¡¨ã¨ã‚°ãƒ©ãƒ•ï¼ˆãƒ”ãƒœãƒƒãƒˆï¼‰ãŒåˆ¥ã‚·ãƒ¼ãƒˆã«å«ã¾ã‚Œã¾ã™ã€‚"
                )
            else:
                st.button("â¬‡ï¸ Excel (ãƒ‡ãƒ¼ã‚¿ãªã—)", disabled=True, use_container_width=True)

if __name__ == "__main__":
    main()

